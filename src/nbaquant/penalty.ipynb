{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalty Measure of Foul Baiting using Poisson Distribution\n",
    "\n",
    "## Project Outline\n",
    "\n",
    "1. **Introduction**\n",
    "   - Overview of the project\n",
    "   - Goals and objectives\n",
    "\n",
    "2. **Data Collection**\n",
    "   - Import necessary libraries\n",
    "   - Fetch player data from the NBA API\n",
    "\n",
    "3. **Data Processing**\n",
    "   - Load data into a Pandas DataFrame\n",
    "   - Data cleaning and transformation\n",
    "\n",
    "4. **Data Analysis**\n",
    "   - Exploratory data analysis (EDA)\n",
    "   - Visualizations\n",
    "\n",
    "5. **Conclusion**\n",
    "   - Summary of findings\n",
    "   - Future work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python\n",
    "\n",
    "This project is written in Python, which means that Python must be installed in your environment to run the project. The minimum supported version is 3.10.\n",
    "\n",
    "#### Windows\n",
    "\n",
    "You can use the Windows package manager `winget`, or the [installer](https://www.python.org/downloads/windows/) from the website.\n",
    "```powershell\n",
    "# you can change the version in the package name to your desired version\n",
    "winget install Python.Python.3.12\n",
    "```\n",
    "\n",
    "#### MacOS\n",
    "Python is already installed by default on recent versions of MacOS. If you have an older version that is not supported, you can use the [Homebrew](https://brew.sh/) package manager to install it, or the [installer](https://www.python.org/downloads/macos/) from the website.\n",
    "```zsh\n",
    "brew install python\n",
    "```\n",
    "\n",
    "#### Linux\n",
    "Python is already installed by default on most distributions of Linux. If it isn't, you can use your distribution's package manager to install Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "\n",
    "This project uses [uv](https://github.com/astral-sh/uv) to manage its dependencies. You can install the dependencies with the `uv` command:\n",
    "\n",
    "`uv add pandas`\n",
    "\n",
    "If you don't want to use `uv`, a `requirements.txt` is also provided. You can install this using `pip`:\n",
    "\n",
    "`pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Variables\n",
    "\n",
    "We will load all our environment variables from a `.env` file, if one is provided.\n",
    "\n",
    "If database information is provided, all dataframes used for analysis are uploaded to it. We use [Microsoft SQL Server](https://www.microsoft.com/en-us/sql-server/sql-server-downloads) by default but any kind of database is supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "DB_TYPE = os.getenv(\"DB_TYPE\", \"sqlserver\")\n",
    "DB_USER = os.getenv(\"DB_USER\", \"sqladmin\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\", \"localhost\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\", \"1433\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"dataframes\")\n",
    "DB_DRIVER = os.getenv(\"DB_DRIVER\")  # some databases require a database driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presentation\n",
    "\n",
    "By default, Pandas dataframes are truncated when they are printed. We want to be able to view all of the data at once, so we embed the dataframe in a scrollable element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "def custom_scrollable_display(df: pd.DataFrame, max_height=400):\n",
    "    \"\"\"\n",
    "    Custom display function to render DataFrames as scrollable elements.\n",
    "\n",
    "    Parameters:\n",
    "    - df: The DataFrame to display.\n",
    "    - max_height: The maximum height of the scrollable area in pixels.\n",
    "    \"\"\"\n",
    "    style = f\"\"\"\n",
    "    <style>\n",
    "    .scrollable-dataframe {{\n",
    "        display: inline-block;\n",
    "        white-space: nowrap;\n",
    "        overflow-x: scroll;\n",
    "        max-height: {max_height}px;\n",
    "        overflow-y: scroll;\n",
    "    }}\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    display(HTML(style + f'<div class=\"scrollable-dataframe\">{df.to_html()}</div>'))\n",
    "\n",
    "\n",
    "def custom_display_hook(df):\n",
    "    custom_scrollable_display(df)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# hook up the custom display function to the automatic printer\n",
    "InteractiveShell.instance().display_formatter.formatters[\"text/html\"].for_type(\n",
    "    pd.DataFrame, custom_display_hook\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Commit Hooks (Developer Only)\n",
    "\n",
    "This notebook uses `nbstripout` to strip notebook output from Git commits. If you are committing code, please run the following command to set up the Git filter.\n",
    "\n",
    "Poetry is required for the pre-commit hooks, so make sure it is installed before you commit code. You will also need to add the plugin `poetry-plugin-export` in order to run the export hook.\n",
    "```bash\n",
    "poetry self add poetry-plugin-export\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbstripout --install\n",
    "!pre-commit install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "\n",
    "### Fetch Player Data from NBA API\n",
    "\n",
    "`nba_api` provides static player and team information, which we will download here so that we can reuse it without requesting the API unnecessarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.static import players, teams\n",
    "\n",
    "DATA_DIR = \"../../data\"\n",
    "\n",
    "PLAYERS_LIST_FILE = \"players_list.csv\"\n",
    "TEAMS_LIST_FILE = \"teams_list.csv\"\n",
    "\n",
    "if os.path.exists(f\"{DATA_DIR}/{PLAYERS_LIST_FILE}\"):\n",
    "    players_list = pd.read_csv(f\"{DATA_DIR}/{PLAYERS_LIST_FILE}\")\n",
    "else:\n",
    "    players_list = pd.DataFrame(players.get_players())\n",
    "    players_list.to_csv(f\"{DATA_DIR}/{PLAYERS_LIST_FILE}\")\n",
    "\n",
    "if os.path.exists(f\"{DATA_DIR}/{TEAMS_LIST_FILE}\"):\n",
    "    teams_list = pd.read_csv(f\"{DATA_DIR}/{TEAMS_LIST_FILE}\")\n",
    "else:\n",
    "    teams_list = pd.DataFrame(teams.get_teams())\n",
    "    teams_list.to_csv(f\"{DATA_DIR}/{TEAMS_LIST_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Game Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're only interested in games that are either in the regular season or in the playoffs. We'll add an enum to distinguish the type of game and use it to differentiate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class SeasonType(Enum):\n",
    "    PRESEASON = 1\n",
    "    REGULAR_SEASON = 2\n",
    "    ALL_STAR = 3\n",
    "    PLAYOFFS = 4\n",
    "    PLAY_IN = 5\n",
    "    NBA_CUP = 6\n",
    "\n",
    "\n",
    "class Season:\n",
    "    def __init__(self, season_id: int) -> None:\n",
    "        season_id_str = str(season_id)\n",
    "        self.season_type = SeasonType(int(season_id_str[0]))\n",
    "        self.season_year = int(season_id_str[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import leaguegamefinder\n",
    "from nba_api.stats.library.parameters import LeagueIDNullable\n",
    "\n",
    "START_SEASON = 2023\n",
    "END_SEASON = 2024\n",
    "GAMES_LIST_FILE = \"games_list.csv\"\n",
    "if os.path.exists(f\"{DATA_DIR}/{GAMES_LIST_FILE}\"):\n",
    "    games_list: pd.DataFrame = pd.read_csv(f\"{DATA_DIR}/{GAMES_LIST_FILE}\")\n",
    "else:\n",
    "    games_list = pd.DataFrame()\n",
    "    for season in range(START_SEASON, END_SEASON + 1):\n",
    "        # put season into the correct form e.g. 2023 -> 2023-24\n",
    "        season_str = f\"{season}-{str(season + 1)[2:]}\"\n",
    "        print(f\"Fetching games for season: {season_str}\", end=\"\\r\")\n",
    "        gamefinder = leaguegamefinder.LeagueGameFinder(\n",
    "            season_nullable=season_str, league_id_nullable=LeagueIDNullable.nba\n",
    "        )\n",
    "        games = gamefinder.get_data_frames()[0]\n",
    "        games_list = pd.concat([games_list, games], ignore_index=True)\n",
    "        time.sleep(0.6)\n",
    "    games_list.to_csv(f\"{DATA_DIR}/{GAMES_LIST_FILE}\", index=False)\n",
    "# games_list[\"SEASON_ID\"].unique()\n",
    "# games_list.loc[(games_list[\"TEAM_NAME\"] == \"San Antonio Spurs\") & (games_list[\"SEASON_ID\"] == 22023)]\n",
    "games_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Play by Plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import playbyplayv3\n",
    "from requests.exceptions import ReadTimeout\n",
    "\n",
    "# took 483 minutes to download up to 2012\n",
    "PBP_LIST_FILE = \"../../data/pbp_list.csv\"\n",
    "if os.path.exists(PBP_LIST_FILE):\n",
    "    pbp_list = pd.read_csv(PBP_LIST_FILE)\n",
    "else:\n",
    "    unique_games_list = games_list.drop_duplicates(subset=\"GAME_ID\")\n",
    "    pbp_list = pd.DataFrame()\n",
    "    for index, row in unique_games_list.iterrows():\n",
    "        err = False\n",
    "        game_id = row[\"GAME_ID\"]\n",
    "        game_date = row[\"GAME_DATE\"]\n",
    "        season_id = row[\"SEASON_ID\"]\n",
    "        season = Season(season_id)\n",
    "        if (\n",
    "            season.season_type != SeasonType.REGULAR_SEASON\n",
    "            and season.season_type != SeasonType.PLAYOFFS\n",
    "        ):\n",
    "            continue\n",
    "        print(f\"Fetching play by play for game {game_id} on {game_date}\", end=\"\\r\")\n",
    "        while True:\n",
    "            try:\n",
    "                pbpfinder = playbyplayv3.PlayByPlayV3(f\"{game_id:010}\")\n",
    "                break\n",
    "            except ReadTimeout as e:\n",
    "                print(f\"{e}! Try again\")\n",
    "            except Exception:\n",
    "                with open(\"../data/err.log\", \"a\") as f:\n",
    "                    print(f\"{game_id} does not have a play by play\", file=f)\n",
    "                err = True\n",
    "                break\n",
    "        if err:\n",
    "            continue\n",
    "        pbp = pbpfinder.get_data_frames()[0]\n",
    "        pbp_list = pd.concat([pbp_list, pbp], ignore_index=True)\n",
    "        time.sleep(0.6)\n",
    "    pbp_list.to_csv(PBP_LIST_FILE, index=False)\n",
    "pbp_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Box Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import boxscoreplayertrackv3\n",
    "from requests.exceptions import ReadTimeout\n",
    "\n",
    "# took 483 minutes to download up to 2012\n",
    "BOXSCORE_PT_LIST_FILE = \"../../data/boxscore_pt_list.csv\"\n",
    "if os.path.exists(BOXSCORE_PT_LIST_FILE):\n",
    "    boxscore_pt_list = pd.read_csv(BOXSCORE_PT_LIST_FILE)\n",
    "else:\n",
    "    unique_games_list = games_list.drop_duplicates(subset=\"GAME_ID\")\n",
    "    boxscore_pt_list = pd.DataFrame()\n",
    "    for index, row in unique_games_list.iterrows():\n",
    "        err = False\n",
    "        game_id = row[\"GAME_ID\"]\n",
    "        game_date = row[\"GAME_DATE\"]\n",
    "        season_id = row[\"SEASON_ID\"]\n",
    "        season = Season(season_id)\n",
    "        if (\n",
    "            season.season_type != SeasonType.REGULAR_SEASON\n",
    "            and season.season_type != SeasonType.PLAYOFFS\n",
    "        ):\n",
    "            continue\n",
    "        print(f\"Fetching box score for game {game_id} on {game_date}\", end=\"\\r\")\n",
    "        while True:\n",
    "            try:\n",
    "                boxscorefinder = boxscoreplayertrackv3.BoxScorePlayerTrackV3(\n",
    "                    f\"{game_id:010}\"\n",
    "                )\n",
    "                break\n",
    "            except ReadTimeout as e:\n",
    "                print(f\"{e}! Try again\")\n",
    "            except Exception:\n",
    "                with open(\"../data/err.log\", \"a\") as f:\n",
    "                    print(f\"{game_id} does not have a player track box score\", file=f)\n",
    "                err = True\n",
    "                break\n",
    "        if err:\n",
    "            continue\n",
    "        boxscore_pt = boxscorefinder.get_data_frames()[0]\n",
    "        boxscore_pt_list = pd.concat([boxscore_pt_list, boxscore_pt], ignore_index=True)\n",
    "        time.sleep(0.6)\n",
    "    boxscore_pt_list.to_csv(BOXSCORE_PT_LIST_FILE, index=False)\n",
    "boxscore_pt_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our analysis will consider only the last two years, so we'll get rid of data from before that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_year = games_list[\"SEASON_ID\"].astype(str).str[1:].astype(int)\n",
    "games_list[\"season_year\"] = season_year\n",
    "current_season_year = 2023  # Replace with the current season's start year\n",
    "games_list = games_list[\n",
    "    games_list[\"season_year\"].isin([current_season_year, current_season_year - 1])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp_list = pbp_list[pbp_list[\"gameId\"].isin(games_list[\"GAME_ID\"].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxscore_pt_list = boxscore_pt_list[\n",
    "    boxscore_pt_list[\"gameId\"].isin(games_list[\"GAME_ID\"].unique())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unnecessary Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of this data isn't useful to us, so we'll drop it to ignore the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp_columns_to_drop = [\n",
    "    \"actionNumber\",\n",
    "    \"pointsTotal\",\n",
    "    \"videoAvailable\",\n",
    "    \"actionId\",\n",
    "    \"playerNameI\",\n",
    "    \"teamTricode\",\n",
    "]\n",
    "pbp_list.drop(\n",
    "    columns=[col for col in pbp_columns_to_drop if col in pbp_list.columns],\n",
    "    inplace=True,\n",
    ")\n",
    "pbp_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bspt_columns_to_drop = [\n",
    "    \"teamCity\",\n",
    "    \"teamName\",\n",
    "    \"teamTricode\",\n",
    "    \"teamSlug\",\n",
    "    \"playerNameI\",\n",
    "    \"teamTricode\",\n",
    "    \"playerSlug\",\n",
    "    \"jerseyNum\",\n",
    "]\n",
    "boxscore_pt_list.drop(\n",
    "    columns=[col for col in bspt_columns_to_drop if col in boxscore_pt_list.columns],\n",
    "    inplace=True,\n",
    ")\n",
    "boxscore_pt_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save on memory, we will also turn variables that can be understood as categorical variables into that type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp_categorical_columns = [\n",
    "    \"gameId\",\n",
    "    \"teamId\",\n",
    "    \"shotResult\",\n",
    "    \"isFieldGoal\",\n",
    "    \"location\",\n",
    "    \"actionType\",\n",
    "    \"subType\",\n",
    "    \"personId\",\n",
    "    \"playerName\",\n",
    "]\n",
    "pbp_list[pbp_categorical_columns] = pbp_list[pbp_categorical_columns].astype(\"category\")\n",
    "pbp_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bspt_categorical_columns = [\n",
    "    \"gameId\",\n",
    "    \"teamId\",\n",
    "    \"personId\",\n",
    "    \"firstName\",\n",
    "    \"familyName\",\n",
    "    \"nameI\",\n",
    "    \"position\",\n",
    "]\n",
    "boxscore_pt_list[bspt_categorical_columns] = boxscore_pt_list[\n",
    "    bspt_categorical_columns\n",
    "].astype(\"category\")\n",
    "boxscore_pt_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll transform the clock data from a string into the total number of seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pbp_list[\"clock\"].dtype != \"int64\":\n",
    "    pbp_list[\"clock\"] = pbp_list[\"clock\"].astype(str)\n",
    "    pbp_list[\"minutes\"] = pbp_list[\"clock\"].str[2:4].astype(int)\n",
    "    pbp_list[\"seconds\"] = pbp_list[\"clock\"].str[5:7].astype(int)\n",
    "    pbp_list[\"clock\"] = pbp_list[\"minutes\"] * 60 + pbp_list[\"seconds\"]\n",
    "    pbp_list.drop(columns=[\"minutes\", \"seconds\"], inplace=True)\n",
    "pbp_list[\"clock\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if boxscore_pt_list[\"minutes\"].dtype != \"int64\":\n",
    "    boxscore_pt_list[\"minutes\"] = boxscore_pt_list[\"minutes\"].astype(str)\n",
    "    boxscore_pt_list[\"mins\"] = boxscore_pt_list[\"minutes\"].str[:-3].astype(int)\n",
    "    boxscore_pt_list[\"seconds\"] = boxscore_pt_list[\"minutes\"].str[-2:].astype(int)\n",
    "    boxscore_pt_list[\"minutes\"] = (\n",
    "        boxscore_pt_list[\"mins\"] * 60 + boxscore_pt_list[\"seconds\"]\n",
    "    )\n",
    "    boxscore_pt_list.drop(columns=[\"mins\", \"seconds\"], inplace=True)\n",
    "boxscore_pt_list[\"minutes\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the foul data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import numpy as np\n",
    "from scipy.stats import poisson\n",
    "\n",
    "\n",
    "fouls_df: pd.DataFrame = pbp_list[pbp_list[\"actionType\"] == \"Foul\"].copy()\n",
    "\n",
    "# Step 2: Group by game, period, and team.\n",
    "# We use \"gameId\", \"period\", and \"teamId\" as grouping keys.\n",
    "grouped = fouls_df.groupby([\"gameId\", \"period\", \"teamId\"])\n",
    "\n",
    "# Prepare a list to collect the data.\n",
    "records: list[dict[str, Any]] = []\n",
    "\n",
    "# Process each group.\n",
    "for (game_id, period, team_id), group in grouped:\n",
    "    # Sort events in descending order by clock.\n",
    "    # In many play-by-play datasets, the clock counts down, so higher values are earlier in the quarter.\n",
    "    group_sorted = group.sort_values(by=\"clock\", ascending=False)\n",
    "\n",
    "    # Extract the clock times of the fouls.\n",
    "    foul_times: list = group_sorted[\"clock\"].tolist()\n",
    "\n",
    "    # Pre-penalty fouls: the first five foul times.\n",
    "    pre_penalty_times: list = foul_times[:5]\n",
    "\n",
    "    # Ensure we have five columns (fill with np.nan if not enough fouls).\n",
    "    pre_penalty_times += [np.nan] * (5 - len(pre_penalty_times))\n",
    "\n",
    "    # Total fouls in the quarter.\n",
    "    total_fouls: int = len(foul_times)\n",
    "\n",
    "    # Post-penalty fouls: count after the first five.\n",
    "    fouls_post_penalty: int = max(total_fouls - 5, 0)\n",
    "\n",
    "    # Create a record.\n",
    "    record = {\n",
    "        \"game_id\": game_id,\n",
    "        \"team_id\": team_id,\n",
    "        \"period\": period,\n",
    "        \"foul_time_1\": pre_penalty_times[0],\n",
    "        \"foul_time_2\": pre_penalty_times[1],\n",
    "        \"foul_time_3\": pre_penalty_times[2],\n",
    "        \"foul_time_4\": pre_penalty_times[3],\n",
    "        \"foul_time_5\": pre_penalty_times[4],\n",
    "        \"fouls_post_penalty\": fouls_post_penalty,\n",
    "        # Also store the count of pre-penalty fouls (could be useful later)\n",
    "        \"fouls_pre_penalty\": min(total_fouls, 5),\n",
    "    }\n",
    "    records.append(record)\n",
    "\n",
    "# Create the penalty_fouls DataFrame.\n",
    "penalty_fouls: pd.DataFrame = pd.DataFrame(records)\n",
    "\n",
    "# Step 4: Merge with team names from games_list.\n",
    "# First, merge to get the team name for the team in question.\n",
    "games_subset: pd.DataFrame = games_list[[\"GAME_ID\", \"TEAM_ID\", \"TEAM_NAME\"]].copy()\n",
    "games_subset.rename(\n",
    "    columns={\"GAME_ID\": \"game_id\", \"TEAM_ID\": \"team_id\", \"TEAM_NAME\": \"team_name\"},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "penalty_fouls = penalty_fouls.merge(games_subset, on=[\"game_id\", \"team_id\"], how=\"left\")\n",
    "\n",
    "# Next, get the opponent's name for each game.\n",
    "# For each record, the opponent is the team in games_list for the same game_id with a different team_id.\n",
    "# We create a mapping from game_id to the two teams.\n",
    "opponent_mapping: dict[str, dict[int, str]] = {}\n",
    "\n",
    "# Create a dictionary that maps game_id to a dict of team_id: team_name.\n",
    "for _, row in games_subset.iterrows():\n",
    "    g_id = row[\"game_id\"]\n",
    "    t_id = row[\"team_id\"]\n",
    "    t_name = row[\"team_name\"]\n",
    "    if g_id not in opponent_mapping:\n",
    "        opponent_mapping[g_id] = {}\n",
    "    opponent_mapping[g_id][t_id] = t_name\n",
    "\n",
    "\n",
    "# Define a helper function to get the opponent's name.\n",
    "def get_opponent_name(game_id: str, team_id: int) -> str:\n",
    "    teams: dict[int, str] = opponent_mapping.get(game_id, {})\n",
    "    # The opponent is the team whose id is not team_id.\n",
    "    for t_id, t_name in teams.items():\n",
    "        if t_id != team_id:\n",
    "            return t_name\n",
    "    return np.nan  # In case there is no opponent found.\n",
    "\n",
    "\n",
    "# Apply the function to create an \"opponent_name\" column.\n",
    "penalty_fouls[\"opponent_name\"] = penalty_fouls.apply(\n",
    "    lambda row: get_opponent_name(row[\"game_id\"], row[\"team_id\"]), axis=1\n",
    ")\n",
    "\n",
    "# Optionally, drop the team_id column if not needed.\n",
    "penalty_fouls.drop(columns=[\"team_id\"], inplace=True)\n",
    "\n",
    "# Rearranging the columns to match the desired order.\n",
    "penalty_fouls = penalty_fouls[\n",
    "    [\n",
    "        \"game_id\",\n",
    "        \"team_name\",\n",
    "        \"opponent_name\",\n",
    "        \"foul_time_1\",\n",
    "        \"foul_time_2\",\n",
    "        \"foul_time_3\",\n",
    "        \"foul_time_4\",\n",
    "        \"foul_time_5\",\n",
    "        \"period\",\n",
    "        \"fouls_post_penalty\",\n",
    "        \"fouls_pre_penalty\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get empirical pmfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the total fouls per quarter (pre + post)\n",
    "penalty_fouls[\"total_fouls\"] = (\n",
    "    penalty_fouls[\"fouls_pre_penalty\"] + penalty_fouls[\"fouls_post_penalty\"]\n",
    ")\n",
    "\n",
    "# Compute the empirical PMF for total quarter fouls\n",
    "total_counts: pd.Series = penalty_fouls[\"total_fouls\"].value_counts().sort_index()\n",
    "empirical_total: pd.Series = total_counts / total_counts.sum()\n",
    "\n",
    "# Compute the empirical PMF for post-penalty fouls\n",
    "pre_counts: pd.Series = penalty_fouls[\"fouls_pre_penalty\"].value_counts().sort_index()\n",
    "empirical_pre: pd.Series = pre_counts / pre_counts.sum()\n",
    "\n",
    "# Compute the empirical PMF for post-penalty fouls\n",
    "post_counts: pd.Series = penalty_fouls[\"fouls_post_penalty\"].value_counts().sort_index()\n",
    "empirical_post: pd.Series = post_counts / post_counts.sum()\n",
    "\n",
    "print(\"Empirical PMF for total quarter fouls (pre + post):\")\n",
    "print(empirical_total)\n",
    "print(\"\\nEmpirical PMF for pre-penalty fouls:\")\n",
    "print(empirical_post)\n",
    "print(\"\\nEmpirical PMF for post-penalty fouls:\")\n",
    "print(empirical_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empirical post-penalty pmf conditioned on the penalty occurring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only rows where the fifth pre-penalty foul occurred\n",
    "penalty_fouls_conditioned = penalty_fouls[penalty_fouls[\"foul_time_5\"].notna()]\n",
    "\n",
    "# Compute the empirical PMF for post-penalty fouls, given that five pre-penalty fouls occurred\n",
    "post_counts_conditioned: pd.Series = (\n",
    "    penalty_fouls_conditioned[\"fouls_post_penalty\"].value_counts().sort_index()\n",
    ")\n",
    "empirical_post_conditioned: pd.Series = (\n",
    "    post_counts_conditioned / post_counts_conditioned.sum()\n",
    ")\n",
    "\n",
    "print(\"Empirical PMF for post-penalty fouls (conditioned on 5 pre-penalty fouls):\")\n",
    "print(empirical_post_conditioned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Penalty Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate λ for standard Poisson distribution of post-penalty fouls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Estimate the Poisson distribution.\n",
    "# For the pre-penalty fouls, the count per observation is min(total fouls, 5).\n",
    "# Create fouls_pre_penalty column by counting non-NaN values in the first five foul time columns.\n",
    "\n",
    "# For the post-penalty fouls, we already computed \"fouls_post_penalty\".\n",
    "# Compute the average rate for post-penalty fouls.\n",
    "lambda_post: float = penalty_fouls[\"fouls_post_penalty\"].mean()\n",
    "\n",
    "print(\n",
    "    \"Estimated Poisson parameter (λ) for post-penalty fouls: {:.3f}\".format(lambda_post)\n",
    ")\n",
    "\n",
    "# Additionally, you can compute the probability mass function (PMF) for a range of counts.\n",
    "# For example, for counts from 0 to 10, using the estimated λ's.\n",
    "x_vals = np.arange(0, 11)\n",
    "\n",
    "pmf_post = poisson.pmf(x_vals, lambda_post)\n",
    "\n",
    "print(\"\\nPMF for post-penalty fouls (counts 0-10):\")\n",
    "for x, pmf in zip(x_vals, pmf_post):\n",
    "    print(\"Fouls = {}: Probability = {:.4f}\".format(x, pmf))\n",
    "penalty_fouls[\"fouls_post_penalty\"]\n",
    "post_counts_conditioned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate for standard Poisson using conditional post-penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_post_conditional: float = post_counts_conditioned.mean()\n",
    "\n",
    "print(\n",
    "    \"Estimated Poisson parameter (λ) for post-penalty fouls: {:.3f}\".format(\n",
    "        lambda_post_conditional\n",
    "    )\n",
    ")\n",
    "\n",
    "# Additionally, you can compute the probability mass function (PMF) for a range of counts.\n",
    "# For example, for counts from 0 to 10, using the estimated λ's.\n",
    "x_vals = np.arange(0, 11)\n",
    "\n",
    "pmf_post_conditional = poisson.pmf(x_vals, lambda_post_conditional)\n",
    "\n",
    "print(\"\\nPMF for post-penalty fouls (counts 0-10):\")\n",
    "for x, pmf in zip(x_vals, pmf_post_conditional):\n",
    "    print(\"Fouls = {}: Probability = {:.4f}\".format(x, pmf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph post-penalty distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import poisson\n",
    "\n",
    "# Assume lambda_pre and lambda_post are already estimated from your data.\n",
    "\n",
    "# Define x-values:\n",
    "# For pre-penalty, our observed values range from 0 to 5.\n",
    "x_vals_pre: np.ndarray = np.arange(0, 6)\n",
    "# For post-penalty, we can use a wider range (e.g., 0 to 10).\n",
    "x_vals_post: np.ndarray = np.arange(0, 11)\n",
    "\n",
    "# Convert empirical PMF series to arrays for plotting.\n",
    "x_total: np.ndarray = empirical_total.index.to_numpy()\n",
    "y_total: np.ndarray = empirical_total.values\n",
    "\n",
    "x_post_empirical: np.ndarray = empirical_post.index.to_numpy()\n",
    "y_post_empirical: np.ndarray = empirical_post.values\n",
    "\n",
    "x_post_conditioned: np.ndarray = empirical_post_conditioned.index.to_numpy()\n",
    "y_post_conditioned: np.ndarray = empirical_post_conditioned.values\n",
    "\n",
    "# Calculate the standard Poisson PMF for post-penalty fouls.\n",
    "pmf_post: np.ndarray = poisson.pmf(x_vals_post, lambda_post)\n",
    "\n",
    "# Create the graph.\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot empirical PMF for total quarter fouls (solid line with circles)\n",
    "plt.plot(\n",
    "    x_total,\n",
    "    y_total,\n",
    "    marker=\"o\",\n",
    "    linestyle=\"-\",\n",
    "    color=\"C3\",\n",
    "    label=\"Empirical Total Quarter Fouls\",\n",
    ")\n",
    "\n",
    "# Plot empirical PMF for post-penalty fouls (dashed line with triangle markers)\n",
    "plt.plot(\n",
    "    x_post_empirical,\n",
    "    y_post_empirical,\n",
    "    marker=\"^\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"C4\",\n",
    "    label=\"Empirical Post-Penalty Fouls\",\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    x_post_conditioned,\n",
    "    y_post_conditioned,\n",
    "    marker=\"*\",\n",
    "    linestyle=\"solid\",\n",
    "    label=\"Empirical (Post-Penalty | 5 Pre Fouls)\",\n",
    ")\n",
    "\n",
    "# Plot the standard Poisson PMF for post-penalty fouls as a solid line with markers.\n",
    "plt.plot(\n",
    "    x_vals_post,\n",
    "    pmf_post,\n",
    "    linestyle=\"-\",\n",
    "    marker=\"s\",\n",
    "    color=\"C1\",\n",
    "    label=f\"Post-Penalty (λ = {lambda_post:.2f})\",\n",
    ")\n",
    "\n",
    "plt.title(\"Foul Count Distributions\")\n",
    "plt.xlabel(\"Number of Fouls\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Penalty Distributions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate λ for truncated Poisson distribution for pre-penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.stats import poisson\n",
    "\n",
    "\n",
    "def neg_log_likelihood(lam: float, data: np.ndarray, max_val: int) -> float:\n",
    "    \"\"\"\n",
    "    Compute the negative log-likelihood for a truncated Poisson distribution.\n",
    "\n",
    "    The PMF for a truncated Poisson (truncated at max_val) is:\n",
    "      f(x; lam) = [e^(-lam) lam^x / x!] / (sum_{j=0}^{max_val} e^(-lam) lam^j / j!)\n",
    "\n",
    "    Parameters:\n",
    "        lam (float): Poisson rate parameter (lambda).\n",
    "        data (np.ndarray): Array of observed counts (0 to max_val).\n",
    "        max_val (int): The truncation point.\n",
    "\n",
    "    Returns:\n",
    "        float: Negative log-likelihood value.\n",
    "    \"\"\"\n",
    "    if lam <= 0:\n",
    "        return np.inf  # Return a large value if lambda is non-positive.\n",
    "\n",
    "    # Normalization constant for the truncated Poisson.\n",
    "    norm_const: float = np.sum(poisson.pmf(np.arange(0, max_val + 1), lam))\n",
    "\n",
    "    # Compute log likelihood.\n",
    "    # Note: np.math.factorial expects an integer input.\n",
    "    log_likelihood: float = 0.0\n",
    "    for x in data:\n",
    "        # Compute log(PMF) = -lam + x*log(lam) - log(x!) - log(norm_const)\n",
    "        log_likelihood += (\n",
    "            -lam\n",
    "            + x * np.log(lam)\n",
    "            - np.log(np.math.factorial(int(x)))\n",
    "            - np.log(norm_const)\n",
    "        )\n",
    "\n",
    "    return -log_likelihood  # We return the negative log-likelihood.\n",
    "\n",
    "\n",
    "# Extract the observed pre-penalty foul counts from the DataFrame.\n",
    "data_pre: np.ndarray = penalty_fouls[\"fouls_pre_penalty\"].to_numpy()\n",
    "max_val: int = 5  # Since the pre-penalty counts are truncated at 5.\n",
    "\n",
    "# Optimize the negative log-likelihood to estimate lambda.\n",
    "result = minimize_scalar(\n",
    "    neg_log_likelihood, bounds=(1e-5, 20), args=(data_pre, max_val), method=\"bounded\"\n",
    ")\n",
    "lambda_pre: float = result.x\n",
    "\n",
    "print(f\"Estimated truncated Poisson lambda for pre-penalty fouls: {lambda_pre:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create function for calculating truncated Poisson pmf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import poisson\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "def truncated_poisson_pmf(\n",
    "    k: Union[int, np.ndarray], lam: float, max_val: int\n",
    ") -> Union[float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Calculate the PMF of a Poisson distribution truncated at max_val.\n",
    "\n",
    "    Parameters:\n",
    "        k (int or np.ndarray): The value(s) for which to compute the PMF (should be between 0 and max_val).\n",
    "        lam (float): The lambda (rate) parameter of the underlying Poisson distribution.\n",
    "        max_val (int): The maximum possible value (truncation point).\n",
    "\n",
    "    Returns:\n",
    "        float or np.ndarray: The truncated PMF evaluated at k.\n",
    "    \"\"\"\n",
    "    # Compute the normalization constant: the sum of Poisson PMFs from 0 to max_val.\n",
    "    norm_const: float = np.sum(poisson.pmf(np.arange(0, max_val + 1), lam))\n",
    "    # Compute the truncated PMF.\n",
    "    return poisson.pmf(k, lam) / norm_const\n",
    "\n",
    "\n",
    "# Example usage for demonstration:\n",
    "lambda_pre_example: float = 3.0  # Replace with your actual estimated lambda_pre\n",
    "x_vals_truncated: np.ndarray = np.arange(0, 6)  # Valid values: 0 to 5 (inclusive)\n",
    "pmf_truncated: np.ndarray = truncated_poisson_pmf(\n",
    "    x_vals_truncated, lambda_pre_example, 5\n",
    ")\n",
    "\n",
    "print(\"Truncated Poisson PMF for pre-penalty fouls (0 to 5):\")\n",
    "for x, prob in zip(x_vals_truncated, pmf_truncated):\n",
    "    print(f\"Fouls = {x}: Probability = {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the truncated Poisson PMF for pre-penalty using the function from Code Block 1.\n",
    "pmf_truncated: np.ndarray = truncated_poisson_pmf(x_vals_pre, lambda_pre, 5)\n",
    "\n",
    "# Create the graph.\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the truncated PMF for pre-penalty fouls using a stem plot.\n",
    "plt.plot(\n",
    "    x_vals_pre,\n",
    "    pmf_truncated,\n",
    "    linestyle=\"-\",\n",
    "    marker=\"o\",\n",
    "    label=f\"Truncated Pre-Penalty (λ = {lambda_pre:.2f})\",\n",
    ")\n",
    "\n",
    "plt.title(\"Foul Count Distributions\")\n",
    "plt.xlabel(\"Number of Fouls\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
