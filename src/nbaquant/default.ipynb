{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Player Data Analysis Project\n",
    "\n",
    "## Project Outline\n",
    "\n",
    "1. **Introduction**\n",
    "   - Overview of the project\n",
    "   - Goals and objectives\n",
    "\n",
    "2. **Data Collection**\n",
    "   - Import necessary libraries\n",
    "   - Fetch player data from the NBA API\n",
    "\n",
    "3. **Data Processing**\n",
    "   - Load data into a Pandas DataFrame\n",
    "   - Data cleaning and transformation\n",
    "\n",
    "4. **Data Analysis**\n",
    "   - Exploratory data analysis (EDA)\n",
    "   - Visualizations\n",
    "\n",
    "5. **Conclusion**\n",
    "   - Summary of findings\n",
    "   - Future work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python\n",
    "\n",
    "This project is written in Python, which means that Python must be installed in your environment to run the project. The minimum supported version is 3.10.\n",
    "\n",
    "#### Windows\n",
    "\n",
    "You can use the Windows package manager `winget`, or the [installer](https://www.python.org/downloads/windows/) from the website.\n",
    "```powershell\n",
    "# you can change the version in the package name to your desired version\n",
    "winget install Python.Python.3.12\n",
    "```\n",
    "\n",
    "#### MacOS\n",
    "Python is already installed by default on recent versions of MacOS. If you have an older version that is not supported, you can use the [Homebrew](https://brew.sh/) package manager to install it, or the [installer](https://www.python.org/downloads/macos/) from the website.\n",
    "```zsh\n",
    "brew install python\n",
    "```\n",
    "\n",
    "#### Linux\n",
    "Python is already installed by default on most distributions of Linux. If it isn't, you can use your distribution's package manager to install Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "\n",
    "This project uses [uv](https://github.com/astral-sh/uv) to manage its dependencies. You can install the dependencies with the `uv` command:\n",
    "\n",
    "`uv add pandas`\n",
    "\n",
    "If you don't want to use `uv`, a `requirements.txt` is also provided. You can install this using `pip`:\n",
    "\n",
    "`pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Variables\n",
    "\n",
    "We will load all our environment variables from a `.env` file, if one is provided.\n",
    "\n",
    "If database information is provided, all dataframes used for analysis are uploaded to it. We use [Microsoft SQL Server](https://www.microsoft.com/en-us/sql-server/sql-server-downloads) by default but any kind of database is supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "DB_TYPE = os.getenv(\"DB_TYPE\", \"sqlserver\")\n",
    "DB_USER = os.getenv(\"DB_USER\", \"sqladmin\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\", \"localhost\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\", \"1433\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"dataframes\")\n",
    "DB_DRIVER = os.getenv(\"DB_DRIVER\")  # some databases require a database driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presentation\n",
    "\n",
    "By default, Pandas dataframes are truncated when they are printed. We want to be able to view all of the data at once, so we embed the dataframe in a scrollable element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "def custom_scrollable_display(df: pd.DataFrame, max_height=400):\n",
    "    \"\"\"\n",
    "    Custom display function to render DataFrames as scrollable elements.\n",
    "\n",
    "    Parameters:\n",
    "    - df: The DataFrame to display.\n",
    "    - max_height: The maximum height of the scrollable area in pixels.\n",
    "    \"\"\"\n",
    "    style = f\"\"\"\n",
    "    <style>\n",
    "    .scrollable-dataframe {{\n",
    "        display: inline-block;\n",
    "        white-space: nowrap;\n",
    "        overflow-x: scroll;\n",
    "        max-height: {max_height}px;\n",
    "        overflow-y: scroll;\n",
    "    }}\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    display(HTML(style + f'<div class=\"scrollable-dataframe\">{df.to_html()}</div>'))\n",
    "\n",
    "\n",
    "def custom_display_hook(df):\n",
    "    custom_scrollable_display(df)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# hook up the custom display function to the automatic printer\n",
    "InteractiveShell.instance().display_formatter.formatters[\"text/html\"].for_type(\n",
    "    pd.DataFrame, custom_display_hook\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Commit Hooks (Developer Only)\n",
    "\n",
    "This notebook uses `nbstripout` to strip notebook output from Git commits. If you are committing code, please run the following command to set up the Git filter.\n",
    "\n",
    "`uv` is required for the pre-commit hooks, so make sure it is installed before you commit code. These hooks will keep the `requirements.txt` file updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbstripout --install\n",
    "!pre-commit install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "\n",
    "### Fetch Player Data from NBA API\n",
    "\n",
    "`nba_api` provides static player and team information, which we will download here so that we can reuse it without requesting the API unnecessarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.static import players, teams\n",
    "\n",
    "DATA_DIR = \"../../data\"\n",
    "\n",
    "PLAYERS_LIST_FILE = \"players_list.csv\"\n",
    "TEAMS_LIST_FILE = \"teams_list.csv\"\n",
    "\n",
    "if os.path.exists(f\"{DATA_DIR}/{PLAYERS_LIST_FILE}\"):\n",
    "    players_list = pd.read_csv(f\"{DATA_DIR}/{PLAYERS_LIST_FILE}\")\n",
    "else:\n",
    "    players_list = pd.DataFrame(players.get_players())\n",
    "    players_list.to_csv(f\"{DATA_DIR}/{PLAYERS_LIST_FILE}\")\n",
    "\n",
    "if os.path.exists(f\"{DATA_DIR}/{TEAMS_LIST_FILE}\"):\n",
    "    teams_list = pd.read_csv(f\"{DATA_DIR}/{TEAMS_LIST_FILE}\")\n",
    "else:\n",
    "    teams_list = pd.DataFrame(teams.get_teams())\n",
    "    teams_list.to_csv(f\"{DATA_DIR}/{TEAMS_LIST_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Game Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're only interested in games that are either in the regular season or in the playoffs. We'll add an enum to distinguish the type of game and use it to differentiate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class SeasonType(Enum):\n",
    "    PRESEASON = 1\n",
    "    REGULAR_SEASON = 2\n",
    "    ALL_STAR = 3\n",
    "    PLAYOFFS = 4\n",
    "    PLAY_IN = 5\n",
    "    NBA_CUP = 6\n",
    "\n",
    "\n",
    "class Season:\n",
    "    def __init__(self, season_id: int) -> None:\n",
    "        season_id_str = str(season_id)\n",
    "        self.season_type = SeasonType(int(season_id_str[0]))\n",
    "        self.season_year = int(season_id_str[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import leaguegamefinder\n",
    "from nba_api.stats.library.parameters import LeagueIDNullable\n",
    "\n",
    "START_SEASON = 2023\n",
    "END_SEASON = 2024\n",
    "GAMES_LIST_FILE = \"games_list.csv\"\n",
    "if os.path.exists(f\"{DATA_DIR}/{GAMES_LIST_FILE}\"):\n",
    "    games_list: pd.DataFrame = pd.read_csv(f\"{DATA_DIR}/{GAMES_LIST_FILE}\")\n",
    "else:\n",
    "    games_list = pd.DataFrame()\n",
    "    for season in range(START_SEASON, END_SEASON + 1):\n",
    "        # put season into the correct form e.g. 2023 -> 2023-24\n",
    "        season_str = f\"{season}-{str(season + 1)[2:]}\"\n",
    "        print(f\"Fetching games for season: {season_str}\", end=\"\\r\")\n",
    "        gamefinder = leaguegamefinder.LeagueGameFinder(\n",
    "            season_nullable=season_str, league_id_nullable=LeagueIDNullable.nba\n",
    "        )\n",
    "        games = gamefinder.get_data_frames()[0]\n",
    "        games_list = pd.concat([games_list, games], ignore_index=True)\n",
    "        time.sleep(0.6)\n",
    "    games_list.to_csv(f\"{DATA_DIR}/{GAMES_LIST_FILE}\", index=False)\n",
    "# games_list[\"SEASON_ID\"].unique()\n",
    "# games_list.loc[(games_list[\"TEAM_NAME\"] == \"San Antonio Spurs\") & (games_list[\"SEASON_ID\"] == 22023)]\n",
    "games_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Play by Plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import playbyplayv3\n",
    "from requests.exceptions import ReadTimeout\n",
    "\n",
    "# took 483 minutes to download up to 2012\n",
    "PBP_LIST_FILE = \"../../data/pbp_list.csv\"\n",
    "if os.path.exists(PBP_LIST_FILE):\n",
    "    pbp_list = pd.read_csv(PBP_LIST_FILE)\n",
    "else:\n",
    "    unique_games_list = games_list.drop_duplicates(subset=\"GAME_ID\")\n",
    "    pbp_list = pd.DataFrame()\n",
    "    for index, row in unique_games_list.iterrows():\n",
    "        err = False\n",
    "        game_id = row[\"GAME_ID\"]\n",
    "        game_date = row[\"GAME_DATE\"]\n",
    "        season_id = row[\"SEASON_ID\"]\n",
    "        season = Season(season_id)\n",
    "        if (\n",
    "            season.season_type != SeasonType.REGULAR_SEASON\n",
    "            and season.season_type != SeasonType.PLAYOFFS\n",
    "        ):\n",
    "            continue\n",
    "        print(f\"Fetching play by play for game {game_id} on {game_date}\", end=\"\\r\")\n",
    "        while True:\n",
    "            try:\n",
    "                pbpfinder = playbyplayv3.PlayByPlayV3(f\"{game_id:010}\")\n",
    "                break\n",
    "            except ReadTimeout as e:\n",
    "                print(f\"{e}! Try again\")\n",
    "            except Exception:\n",
    "                with open(\"../../data/err.log\", \"a\") as f:\n",
    "                    print(f\"{game_id} does not have a play by play\", file=f)\n",
    "                err = True\n",
    "                break\n",
    "        if err:\n",
    "            continue\n",
    "        pbp = pbpfinder.get_data_frames()[0]\n",
    "        pbp_list = pd.concat([pbp_list, pbp], ignore_index=True)\n",
    "        time.sleep(0.6)\n",
    "    pbp_list.to_csv(PBP_LIST_FILE, index=False)\n",
    "pbp_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Box Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import boxscoreplayertrackv3\n",
    "from requests.exceptions import ReadTimeout\n",
    "\n",
    "# took 483 minutes to download up to 2012\n",
    "BOXSCORE_PT_LIST_FILE = \"../../data/boxscore_pt_list.csv\"\n",
    "if os.path.exists(BOXSCORE_PT_LIST_FILE):\n",
    "    boxscore_pt_list = pd.read_csv(BOXSCORE_PT_LIST_FILE)\n",
    "else:\n",
    "    unique_games_list = games_list.drop_duplicates(subset=\"GAME_ID\")\n",
    "    boxscore_pt_list = pd.DataFrame()\n",
    "    for index, row in unique_games_list.iterrows():\n",
    "        err = False\n",
    "        game_id = row[\"GAME_ID\"]\n",
    "        game_date = row[\"GAME_DATE\"]\n",
    "        season_id = row[\"SEASON_ID\"]\n",
    "        season = Season(season_id)\n",
    "        if (\n",
    "            season.season_type != SeasonType.REGULAR_SEASON\n",
    "            and season.season_type != SeasonType.PLAYOFFS\n",
    "        ):\n",
    "            continue\n",
    "        print(f\"Fetching box score for game {game_id} on {game_date}\", end=\"\\r\")\n",
    "        while True:\n",
    "            try:\n",
    "                boxscorefinder = boxscoreplayertrackv3.BoxScorePlayerTrackV3(\n",
    "                    f\"{game_id:010}\"\n",
    "                )\n",
    "                break\n",
    "            except ReadTimeout as e:\n",
    "                print(f\"{e}! Try again\")\n",
    "            except Exception:\n",
    "                with open(\"../data/err.log\", \"a\") as f:\n",
    "                    print(f\"{game_id} does not have a player track box score\", file=f)\n",
    "                err = True\n",
    "                break\n",
    "        if err:\n",
    "            continue\n",
    "        boxscore_pt = boxscorefinder.get_data_frames()[0]\n",
    "        boxscore_pt_list = pd.concat([boxscore_pt_list, boxscore_pt], ignore_index=True)\n",
    "        time.sleep(0.6)\n",
    "    boxscore_pt_list.to_csv(BOXSCORE_PT_LIST_FILE, index=False)\n",
    "boxscore_pt_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our analysis will consider only the last two years, so we'll get rid of data from before that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_year = games_list[\"SEASON_ID\"].astype(str).str[1:].astype(int)\n",
    "games_list[\"season_year\"] = season_year\n",
    "current_season_year = 2023  # Replace with the current season's start year\n",
    "games_list = games_list[\n",
    "    games_list[\"season_year\"].isin([current_season_year, current_season_year - 1])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp_list = pbp_list[pbp_list[\"gameId\"].isin(games_list[\"GAME_ID\"].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxscore_pt_list = boxscore_pt_list[\n",
    "    boxscore_pt_list[\"gameId\"].isin(games_list[\"GAME_ID\"].unique())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unnecessary Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of this data isn't useful to us, so we'll drop it to ignore the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp_columns_to_drop = [\n",
    "    \"actionNumber\",\n",
    "    \"pointsTotal\",\n",
    "    \"videoAvailable\",\n",
    "    \"actionId\",\n",
    "    \"playerNameI\",\n",
    "    \"teamTricode\",\n",
    "]\n",
    "pbp_list.drop(\n",
    "    columns=[col for col in pbp_columns_to_drop if col in pbp_list.columns],\n",
    "    inplace=True,\n",
    ")\n",
    "pbp_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bspt_columns_to_drop = [\n",
    "    \"teamCity\",\n",
    "    \"teamName\",\n",
    "    \"teamTricode\",\n",
    "    \"teamSlug\",\n",
    "    \"playerNameI\",\n",
    "    \"teamTricode\",\n",
    "    \"playerSlug\",\n",
    "    \"jerseyNum\",\n",
    "]\n",
    "boxscore_pt_list.drop(\n",
    "    columns=[col for col in bspt_columns_to_drop if col in boxscore_pt_list.columns],\n",
    "    inplace=True,\n",
    ")\n",
    "boxscore_pt_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save on memory, we will also turn variables that can be understood as categorical variables into that type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp_categorical_columns = [\n",
    "    \"gameId\",\n",
    "    \"teamId\",\n",
    "    \"shotResult\",\n",
    "    \"isFieldGoal\",\n",
    "    \"location\",\n",
    "    \"actionType\",\n",
    "    \"subType\",\n",
    "    \"personId\",\n",
    "    \"playerName\",\n",
    "]\n",
    "pbp_list[pbp_categorical_columns] = pbp_list[pbp_categorical_columns].astype(\"category\")\n",
    "pbp_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bspt_categorical_columns = [\n",
    "    \"gameId\",\n",
    "    \"teamId\",\n",
    "    \"personId\",\n",
    "    \"firstName\",\n",
    "    \"familyName\",\n",
    "    \"nameI\",\n",
    "    \"position\",\n",
    "]\n",
    "boxscore_pt_list[bspt_categorical_columns] = boxscore_pt_list[\n",
    "    bspt_categorical_columns\n",
    "].astype(\"category\")\n",
    "boxscore_pt_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll transform the clock data from a string into the total number of seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pbp_list[\"clock\"].dtype != \"int64\":\n",
    "    pbp_list[\"clock\"] = pbp_list[\"clock\"].astype(str)\n",
    "    pbp_list[\"minutes\"] = pbp_list[\"clock\"].str[2:4].astype(int)\n",
    "    pbp_list[\"seconds\"] = pbp_list[\"clock\"].str[5:7].astype(int)\n",
    "    pbp_list[\"clock\"] = pbp_list[\"minutes\"] * 60 + pbp_list[\"seconds\"]\n",
    "    pbp_list.drop(columns=[\"minutes\", \"seconds\"], inplace=True)\n",
    "pbp_list[\"clock\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if boxscore_pt_list[\"minutes\"].dtype != \"int64\":\n",
    "    boxscore_pt_list[\"minutes\"] = boxscore_pt_list[\"minutes\"].astype(str)\n",
    "    boxscore_pt_list[\"mins\"] = boxscore_pt_list[\"minutes\"].str[:-3].astype(int)\n",
    "    boxscore_pt_list[\"seconds\"] = boxscore_pt_list[\"minutes\"].str[-2:].astype(int)\n",
    "    boxscore_pt_list[\"minutes\"] = (\n",
    "        boxscore_pt_list[\"mins\"] * 60 + boxscore_pt_list[\"seconds\"]\n",
    "    )\n",
    "    boxscore_pt_list.drop(columns=[\"mins\", \"seconds\"], inplace=True)\n",
    "boxscore_pt_list[\"minutes\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_list.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
