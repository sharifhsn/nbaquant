{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Player Data Analysis Project\n",
    "\n",
    "## Project Outline\n",
    "\n",
    "1. **Introduction**\n",
    "   - Overview of the project\n",
    "   - Goals and objectives\n",
    "\n",
    "2. **Data Collection**\n",
    "   - Import necessary libraries\n",
    "   - Fetch player data from the NBA API\n",
    "\n",
    "3. **Data Processing**\n",
    "   - Load data into a Pandas DataFrame\n",
    "   - Data cleaning and transformation\n",
    "\n",
    "4. **Data Analysis**\n",
    "   - Exploratory data analysis (EDA)\n",
    "   - Visualizations\n",
    "\n",
    "5. **Conclusion**\n",
    "   - Summary of findings\n",
    "   - Future work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python\n",
    "\n",
    "This project is written in Python, which means that Python must be installed in your environment to run the project. The minimum supported version is 3.10.\n",
    "\n",
    "#### Windows\n",
    "\n",
    "You can use the Windows package manager `winget`, or the [installer](https://www.python.org/downloads/windows/) from the website.\n",
    "```powershell\n",
    "# you can change the version in the package name to your desired version\n",
    "winget install Python.Python.3.12\n",
    "```\n",
    "\n",
    "#### MacOS\n",
    "Python is already installed by default on recent versions of MacOS. If you have an older version that is not supported, you can use the [Homebrew](https://brew.sh/) package manager to install it, or the [installer](https://www.python.org/downloads/macos/) from the website.\n",
    "```zsh\n",
    "brew install python\n",
    "```\n",
    "\n",
    "#### Linux\n",
    "Python is already installed by default on most distributions of Linux. If it isn't, you can use your distribution's package manager to install Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Virtual Environment\n",
    "\n",
    "It's generally recommended that you use a virtual environment (or venv) for this project. That way, all dependencies can be installed for the project without affecting the rest of your system. You can create a venv with Python:\n",
    "\n",
    "```bash\n",
    "python -m venv .venv\n",
    "```\n",
    "\n",
    "To activate the virtual environment in your shell, you can use the following commands.\n",
    "\n",
    "On Windows:\n",
    "\n",
    "```powershell\n",
    ".venv\\Scripts\\activate\n",
    "```\n",
    "\n",
    "On other operating systems:\n",
    "\n",
    "```bash\n",
    ".venv/bin/activate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "\n",
    "This project uses [Poetry](https://python-poetry.org/) to manage its dependencies. You can install the dependencies with the `poetry` command:\n",
    "\n",
    "`poetry install`\n",
    "\n",
    "If you don't want to use Poetry, a `requirements.txt` is also provided. You can install this using `pip`:\n",
    "\n",
    "`pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Variables\n",
    "\n",
    "We will load all our environment variables from a `.env` file, if one is provided.\n",
    "\n",
    "This project uses the [BALLDONTLIE](https://app.balldontlie.io/) API, which has a free key available [if you sign up for an account](https://app.balldontlie.io/signup).\n",
    "\n",
    "If database information is provided, all dataframes used for analysis are uploaded to it. We use [Postgres](https://www.postgresql.org/about/) with the [Psycopg](https://www.psycopg.org/psycopg3/) driver by default but any kind of database is supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "BALLDONTLIE_API_KEY = os.getenv(\"BALLDONTLIE_API_KEY\")\n",
    "DB_TYPE = os.getenv(\"DB_TYPE\", \"postgresql+psycopg\")\n",
    "DB_USER = os.getenv(\"DB_USER\", \"postgres\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\", \"localhost\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\", \"5432\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"postgres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presentation\n",
    "\n",
    "By default, Pandas dataframes are truncated when they are printed. We want to be able to view all of the data at once, so we embed the dataframe in a scrollable element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "def custom_scrollable_display(df: pd.DataFrame, max_height=400):\n",
    "    \"\"\"\n",
    "    Custom display function to render DataFrames as scrollable elements.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: The DataFrame to display.\n",
    "    - max_height: The maximum height of the scrollable area in pixels.\n",
    "    \"\"\"\n",
    "    style = f\"\"\"\n",
    "    <style>\n",
    "    .scrollable-dataframe {{\n",
    "        display: inline-block;\n",
    "        white-space: nowrap;\n",
    "        overflow-x: scroll;\n",
    "        max-height: {max_height}px;\n",
    "        overflow-y: scroll;\n",
    "    }}\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    display(HTML(style + f'<div class=\"scrollable-dataframe\">{df.to_html()}</div>'))\n",
    "\n",
    "def custom_display_hook(df):\n",
    "    custom_scrollable_display(df)\n",
    "    return \"\"\n",
    "\n",
    "# hook up the custom display function to the automatic printer\n",
    "InteractiveShell.instance().display_formatter.formatters['text/html'].for_type(pd.DataFrame, custom_display_hook);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Commit Hooks (Developer Only)\n",
    "\n",
    "This notebook uses `nbstripout` to strip notebook output from Git commits. If you are committing code, please run the following command to set up the Git filter.\n",
    "\n",
    "Poetry is required for the pre-commit hooks, so make sure it is installed before you commit code. You will also need to add the plugin `poetry-plugin-export` in order to run the export hook.\n",
    "```bash\n",
    "poetry self add poetry-plugin-export\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbstripout --install\n",
    "!pre-commit install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "\n",
    "### Fetch Player Data from NBA API\n",
    "\n",
    "`nba_api` provides static player and team information, which we will download here so that we can reuse it without requesting the API unnecessarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.static import players, teams\n",
    "PLAYERS_LIST_FILE = \"../data/players_list.json\"\n",
    "TEAMS_LIST_FILE = \"../data/teams_list.json\"\n",
    "\n",
    "if not os.path.exists(PLAYERS_LIST_FILE):\n",
    "    players_list = players.get_players()\n",
    "    with open(PLAYERS_LIST_FILE, \"w\") as f:\n",
    "        json.dump(players_list, f)\n",
    "else:\n",
    "    with open(PLAYERS_LIST_FILE, \"r\") as f:\n",
    "        players_list = json.load(f)\n",
    "if not os.path.exists(TEAMS_LIST_FILE):\n",
    "    teams_list = teams.get_teams()\n",
    "    teams.get_wnba_teams\n",
    "    with open(TEAMS_LIST_FILE, \"w\") as f:\n",
    "        json.dump(teams_list, f)\n",
    "else:\n",
    "    with open(TEAMS_LIST_FILE, \"r\") as f:\n",
    "        teams_list = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Game Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're only interested in games that are either in the regular season or in the playoffs. We'll add an enum to distinguish the type of game and use it to differentiate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class SeasonType(Enum):\n",
    "    PRESEASON = 1\n",
    "    REGULAR_SEASON = 2\n",
    "    ALL_STAR = 3\n",
    "    PLAYOFFS = 4\n",
    "    PLAY_IN = 5\n",
    "    NBA_CUP = 6\n",
    "class Season():\n",
    "    def __init__(self, season_id: int) -> None:\n",
    "        season_id_str = str(season_id)\n",
    "        self.season_type = SeasonType(int(season_id_str[0]))\n",
    "        self.season_year = int(season_id_str[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import leaguegamefinder\n",
    "from nba_api.stats.library.parameters import LeagueIDNullable, LeagueID\n",
    "START_SEASON = 2013\n",
    "END_SEASON = 2023\n",
    "GAMES_LIST_FILE = \"../data/games_list.csv\"\n",
    "if os.path.exists(GAMES_LIST_FILE):\n",
    "    games_list: pd.DataFrame = pd.read_csv(GAMES_LIST_FILE)\n",
    "else:\n",
    "    games_list = pd.DataFrame()\n",
    "    for season in range(START_SEASON, END_SEASON + 1):\n",
    "        # put season into the correct form e.g. 2023 -> 2023-24\n",
    "        season_str = f\"{season}-{str(season + 1)[2:]}\"\n",
    "        print(f\"Fetching games for season: {season_str}\", end=\"\\r\")\n",
    "        gamefinder = leaguegamefinder.LeagueGameFinder(season_nullable=season_str, league_id_nullable=LeagueIDNullable.nba)\n",
    "        games = gamefinder.get_data_frames()[0]\n",
    "        games_list = pd.concat([games_list, games], ignore_index=True)\n",
    "        time.sleep(0.6)\n",
    "    games_list.to_csv(GAMES_LIST_FILE, index=False)\n",
    "# games_list[\"SEASON_ID\"].unique()\n",
    "games_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Play by Plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import playbyplayv3\n",
    "from requests.exceptions import ReadTimeout\n",
    "# 65502 games\n",
    "PBP_LIST_FILE = \"../data/pbp_list.csv\"\n",
    "if os.path.exists(PBP_LIST_FILE):\n",
    "    pbp_list = pd.read_csv(PBP_LIST_FILE)\n",
    "else:\n",
    "    pbp_list = pd.DataFrame()\n",
    "    for index, row in games_list.iterrows():\n",
    "        err = False\n",
    "        game_id = row[\"GAME_ID\"]\n",
    "        game_date = row[\"GAME_DATE\"]\n",
    "        season_id = row[\"SEASON_ID\"]\n",
    "        season = Season(season_id)\n",
    "        if season.season_type != SeasonType.REGULAR_SEASON and season.season_type != SeasonType.PLAYOFFS:\n",
    "            continue\n",
    "        print(f\"Fetching play by play for game on {game_date}\", end=\"\\r\")\n",
    "        while True:\n",
    "            try:\n",
    "                pbpfinder = playbyplayv3.PlayByPlayV3(f\"{game_id:010}\")\n",
    "                break\n",
    "            except ReadTimeout as e:\n",
    "                print(f\"{e}! Try again\")\n",
    "            except IndexError:\n",
    "                print(f\"{game_id} does not have a play by play\")\n",
    "                err = True\n",
    "                break\n",
    "        if err:\n",
    "            continue\n",
    "        pbp = pbpfinder.get_data_frames()[0]\n",
    "        pbp_list = pd.concat([pbp_list, pbp], ignore_index=True)\n",
    "        time.sleep(0.6)\n",
    "    pbp_list.to_csv(PBP_LIST_FILE, index=False)\n",
    "pbp_list.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 00: 30000\n",
    "- 07: 10\n",
    "- 08: 36\n",
    "- 09: 119\n",
    "- 10: 13098\n",
    "- 12: 3094\n",
    "- 13: 85\n",
    "- 14: 320\n",
    "- 15: 2170\n",
    "- 16: 109\n",
    "- 17: 91\n",
    "- 18: 170\n",
    "- 19: 174\n",
    "- 20: 20142\n",
    "- 22: 6053\n",
    "- 25: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ALTERNATIVE, USING NBA_API\n",
    "from nba_api.stats.endpoints import playbyplayv3\n",
    "from nba_api.stats.library.parameters import SeasonType\n",
    "from nba_api.stats.endpoints import leaguegamefinder\n",
    "\n",
    "# Define the season (e.g., '2023-24')\n",
    "season = '2023-24'\n",
    "# season_type = SeasonType.REGULAR  # or SeasonType.PLAYOFFS\n",
    "\n",
    "# Get game IDs\n",
    "gamefinder = leaguegamefinder.LeagueGameFinder(season_nullable=season)\n",
    "games: pd.DataFrame = gamefinder.get_data_frames()[0]\n",
    "game_ids = games['GAME_ID'].tolist()\n",
    "\n",
    "def fetch_play_by_play(game_id: str) -> pd.DataFrame:\n",
    "    pbp = playbyplayv3.PlayByPlayV3(game_id)\n",
    "    return pbp.get_data_frames()[0]\n",
    "play_by_play_data = fetch_play_by_play(game_ids[0])\n",
    "# play_by_play_data[play_by_play_data[\"EVENTMSGACTIONTYPE\"] == 79]\n",
    "game_ids[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we analyze the statistics for each players, we need to get a list of all players that had minutes in the 2023 season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://api.balldontlie.io/v1/\"\n",
    "PLAYERS_ENDPOINT = \"players\"\n",
    "PAGE_100 = \"per_page=100\"\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"{BALLDONTLIE_API_KEY}\"\n",
    "}\n",
    "ALL_PLAYERS_FILE = \"../data/all_players.json\"\n",
    "\n",
    "if os.path.exists(ALL_PLAYERS_FILE):\n",
    "    print(f\"{ALL_PLAYERS_FILE} already exists.\")\n",
    "    with open(ALL_PLAYERS_FILE, \"r\") as f:\n",
    "        all_players = json.load(f)\n",
    "else:\n",
    "    all_players = []\n",
    "    next_cursor = None\n",
    "\n",
    "    while True:\n",
    "        if next_cursor:\n",
    "            url = f\"{BASE_URL}{PLAYERS_ENDPOINT}?{PAGE_100}&cursor={next_cursor}\"\n",
    "        else:\n",
    "            url = f\"{BASE_URL}{PLAYERS_ENDPOINT}?{PAGE_100}\"\n",
    "        \n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            all_players.extend(data[\"data\"])\n",
    "            next_cursor = data[\"meta\"].get(\"next_cursor\")\n",
    "            \n",
    "            if not next_cursor:\n",
    "                break\n",
    "            \n",
    "            time.sleep(2)\n",
    "        else:\n",
    "            print(f\"Request failed with status code {response.status_code}\")\n",
    "            break\n",
    "\n",
    "    # Save all players data to a JSON file\n",
    "    with open(ALL_PLAYERS_FILE, 'w') as f:\n",
    "        json.dump(all_players, f, indent=4)\n",
    "\n",
    "    print(f\"All player data has been saved to {ALL_PLAYERS_FILE}\")\n",
    "\n",
    "print(all_players[0])\n",
    "len(all_players)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This JSON file contains a list of all players in the NBA. We're only concerned with the players from the current season, so we need to eliminate all the players who aren't. One quick heuristic we can use is draft year. Obviously, a player who was drafted in 1986 will not be playing now. We want to pick a cutoff year as close as possible to the currrent year to eliminate as many players as we can. The easiest way to do this is check the oldest players still playing in the NBA, mark them as exceptions, and use their draft year as a starting point.\n",
    "A list of the oldest players still in the NBA can be found at [this Wikipedia page](https://en.wikipedia.org/wiki/List_of_oldest_and_youngest_NBA_players#Active). We chose 2010 as the cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_PLAYERS = [\"LeBron James\", \"Chris Paul\", \"Kyle Lowry\", \"PJ Tucker\", \"Kevin Durant\", \"Al Horford\", \"Mike Conley\", \"Jeff Green\", \"Derrick Rose\", \"Russell Westbrook\", \"Kevin Love\", \"Eric Gordon\", \"Brook Lopez\", \"Nicolas Batum\", \"DeAndre Jordan\", \"James Harden\", \"Stephen Curry\", \"DeMar DeRozan\", \"Jrue Holiday\", \"Taj Gibson\", \"Paul George\"]\n",
    "all_players_after_2010 = [player for player in all_players if player[\"draft_year\"] == None or player[\"draft_year\"] > 2010 or f\"{player['first_name']} {player['last_name']}\" in OLD_PLAYERS]\n",
    "len(all_players_after_2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that we included players that have `null` for their draft year. That's because those players are undrafted. There are some undrafted players currently in the NBA, so we can't exclude them purely based on that fact. The website [2KRatings](https://www.2kratings.com/) maintains [a list](https://www.2kratings.com/lists/undrafted-nba-players) of all active undrafted players. This includes players in the G League, however. We decided to take the top 35 players as, after that point, the players play so few minutes that their stats will have a negligible impact on analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNDRAFTED_PLAYERS = [\"Fred VanVleet\", \"Austin Reaves\", \"Naz Reid\", \"T.J. McConnell\", \"Luguentz Dort\", \"Alex Caruso\", \"Derrick Jones Jr.\", \"Duncan Robinson\", \"Simone Fontecchio\", \"Gary Payton II\", \"Max Strus\", \"Luke Kornet\", \"Jock Landale\", \"Christian Wood\", \"Caleb Martin\", \"Chris Boucher\", \"Dorian Finney-Smith\", \"Robert Covington\", \"Jose Alvarado\", \"Javonte Green\", \"Sam Hauser\", \"Keon Ellis\", \"Duop Reath\", \"Royce O'Neale\", \"Naji Marshall\", \"Scotty Pippen Jr.\", \"Haywood Highsmith\", \"Drew Eubanks\", \"Gabe Vincent\", \"Daniel Theis\", \"Maxi Kleber\", \"Jordan McLaughlin\", \"Jordan Goodwin\", \"Damion Lee\", \"Lamar Stevens\"]\n",
    "all_players_after_2010_without_undrafted = [player for player in all_players_after_2010 if player[\"draft_year\"] != None or f\"{player['first_name']} {player['last_name']}\" in UNDRAFTED_PLAYERS]\n",
    "len(all_players_after_2010_without_undrafted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Stats for each Player\n",
    "\n",
    "Now that we've gotten our list of players, we can get the stats for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATS_ENDPOINT = \"stats\"\n",
    "# we only need stats from the latest season\n",
    "CURRENT_SEASON = \"seasons[]=2023\"\n",
    "ALL_PLAYERS_STATS_FILE = \"../data/all_players_stats.json\"\n",
    "\n",
    "if os.path.exists(ALL_PLAYERS_STATS_FILE):\n",
    "    print(f\"{ALL_PLAYERS_STATS_FILE} already exists.\")\n",
    "    with open(ALL_PLAYERS_STATS_FILE, \"r\") as f:\n",
    "        all_players_stats = json.load(f)\n",
    "else:\n",
    "    all_players_stats = {}\n",
    "    \n",
    "    for index, player in enumerate(all_players_after_2010_without_undrafted):\n",
    "        # we only need to query this once because there are fewer than 100 games in a season\n",
    "        url = f\"{BASE_URL}{STATS_ENDPOINT}?{PAGE_100}&{CURRENT_SEASON}&player_ids[]={player['id']}\"\n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            all_players_stats.update({player[\"id\"]: data[\"data\"]})\n",
    "            print(f\"Downloaded {index} of {len(all_players_after_2010_without_undrafted)}\", end=\"\\r\")\n",
    "            time.sleep(2)\n",
    "        else:\n",
    "            print(f\"Request failed with status code {response.status_code}\")\n",
    "            break\n",
    "    \n",
    "    with open(ALL_PLAYERS_STATS_FILE, \"w\") as f:\n",
    "        json.dump(all_players_stats, f)\n",
    "    \n",
    "    print(f\"All player data has been saved to {ALL_PLAYERS_STATS_FILE}\")\n",
    "\n",
    "print(all_players_stats[\"15\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we've eliminated most of the players who aren't playing in the current season, some false positives remain. We can take care of the ones that didn't play at all by checking to see if their stats are an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_players_stats_current_season = {player_id: stats for player_id, stats in all_players_stats.items() if stats}\n",
    "len(all_players_stats_current_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also only really concerned with players that have significant play time. We generally define this as having an average of at least 16 minutes per game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_players_stats_current_season_with_16_mins = {player_id: stats for player_id, stats in all_players_stats_current_season.items() if sum(int(stat[\"min\"]) for stat in stats) / len(stats) >= 16}\n",
    "len(all_players_stats_current_season_with_16_mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have to exclude games where the players didn't play as those would skew the results, i.e. games where they played 0 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_players_stats_current_season_with_16_mins_and_play_time = {player_id: [stat for stat in stats if int(stat[\"min\"]) > 0] for player_id, stats in all_players_stats_current_season_with_16_mins.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing\n",
    "\n",
    "We used a Pandas dataframe to store these stats for each player. In addition to the direct statistics recorded like points and rebounds, we added an additional `is_home` indicator which is true when the game was played at home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for player_id, stats in all_players_stats_current_season_with_16_mins_and_play_time.items():\n",
    "    desired_stats = [\"fgm\", \"fga\", \"fg_pct\", \"fg3m\", \"fg3a\", \"fg3_pct\", \"ftm\", \"fta\", \"ft_pct\", \"oreb\", \"dreb\", \"reb\", \"ast\", \"stl\", \"blk\", \"turnover\", \"pf\", \"pts\"]\n",
    "    data = {\n",
    "        \"player_id\": int(player_id),\n",
    "        \"player_name\": f\"{stats[0]['player']['first_name']} {stats[0]['player']['last_name']}\",\n",
    "    }\n",
    "    data[\"min\"] = [int(stat[\"min\"]) for stat in stats]\n",
    "    for desired_stat in desired_stats:\n",
    "        data[desired_stat] = [stat[desired_stat] for stat in stats]\n",
    "    data[\"is_home\"] = [stat[\"game\"][\"home_team_id\"] == stat[\"team\"][\"id\"] for stat in stats]\n",
    "    df_player = pd.DataFrame(data=data)\n",
    "    df = pd.concat([df, df_player], ignore_index=True)\n",
    "# df.to_excel(\"NBA_2023_Stats.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in this data, the percentage for field goals, free throws, and 3 point shots is 0 when both attempts and makes are 0. This doesn't really make sense and can skew our results. In order to fix this, we will replace all instances of 0 in this case with `NaN`, so that aggregate analysis will ignore those games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fg_pct\"] = df.apply(lambda row: row[\"fgm\"] / row[\"fga\"] if row[\"fga\"] > 0 else np.nan, axis=1)\n",
    "df[\"fg3_pct\"] = df.apply(lambda row: row[\"fg3m\"] / row[\"fg3a\"] if row[\"fg3a\"] > 0 else np.nan, axis=1)\n",
    "df[\"ft_pct\"] = df.apply(lambda row: row[\"ftm\"] / row[\"fta\"] if row[\"fta\"] > 0 else np.nan, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Analysis\n",
    "\n",
    "In order to analyze this data, it will be useful for us to aggregate this data by player when comparing players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_stats = [\"min\", \"fgm\", \"fga\", \"fg_pct\", \"fg3m\", \"fg3a\", \"fg3_pct\", \"ftm\", \"fta\", \"ft_pct\", \"oreb\", \"dreb\", \"reb\", \"ast\", \"stl\", \"blk\", \"turnover\", \"pf\", \"pts\"]\n",
    "\n",
    "df_grouped = df.groupby(\"player_id\").agg(\n",
    "    player_name=(\"player_name\", \"first\"),\n",
    "    # min=(\"min\", \"mean\"),\n",
    "    # fgm=(\"fgm\", \"mean\"),\n",
    "    # fga=(\"fga\", \"mean\"),\n",
    "    # fg_pct=(\"fg_pct\", \"mean\"),\n",
    "    fg3m=(\"fg3m\", \"mean\"),\n",
    "    fg3a=(\"fg3a\", \"mean\"),\n",
    "    fg3_pct=(\"fg3_pct\", \"mean\"),\n",
    "    # ftm=(\"ftm\", \"mean\"),\n",
    "    # fta=(\"fta\", \"mean\"),\n",
    "    # ft_pct=(\"ft_pct\", \"mean\"),\n",
    "    # oreb=(\"oreb\", \"mean\"),\n",
    "    # dreb=(\"dreb\", \"mean\"),\n",
    "    # reb=(\"reb\", \"std\"),\n",
    "    # ast=(\"ast\", \"mean\"),\n",
    "    # stl=(\"stl\", \"std\"),\n",
    "    # blk=(\"blk\", \"mean\"),\n",
    "    # turnover=(\"turnover\", \"mean\"),\n",
    "    # pf=(\"pf\", \"mean\"),\n",
    "    # pts=(\"pts\", \"var\"),\n",
    "    # is_home=(\"is_home\", \"mean\")\n",
    ")\n",
    "# print(df.groupby(\"player_id\")[\"pts\"].std().reset_index().sort_values(\"pts\"))\n",
    "df_grouped_over_35 = df_grouped[df_grouped[\"fg3_pct\"] > 0.35]\n",
    "df_grouped_over_35_over_3 = df_grouped_over_35[df_grouped_over_35[\"fg3a\"] > 3]\n",
    "df_grouped_over_35_over_3.sort_values(\"fg3_pct\", ascending=False)\n",
    "# df_grouped_over_35_over_3.to_excel(\"3 Point Stats for over 0.35 percentage and 3 makes average.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of shai's scores\n",
    "import scipy.stats\n",
    "\n",
    "stat = \"pts\"\n",
    "df_jaylen = df.loc[df.loc[:, \"player_id\"] == 70, :]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_jaylen.loc[:, stat], bins=20, kde=True, stat=\"density\", color=\"skyblue\", label=\"Steals Histogram\")\n",
    "\n",
    "\n",
    "mu, std = scipy.stats.norm.fit(df_jaylen.loc[:, stat])\n",
    "\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = scipy.stats.norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, \"k\", linewidth=2, label=\"Normal Distribution Fit\")\n",
    "\n",
    "# plt.xlabel(\"Number of Steals\")\n",
    "# plt.ylabel(\"Density\")\n",
    "# plt.title(\"Histogram of Steals with Normal Distribution Fit\")\n",
    "\n",
    "print(scipy.stats.jarque_bera(df_jaylen.loc[:, stat]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Reporting\n",
    "\n",
    "To create our final report from our analysis, we will be using PowerBI. We have a Postgres database that our PowerBI report will import the tables from. If no database is available, the dataframes will instead export as an Excel spreadsheet, which can be manually uploaded to PowerBI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine import reflection\n",
    "DATABASE_URL = f\"{DB_TYPE}://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    display(\"Connection to the database was successful!\")\n",
    "\n",
    "def upload_dataframes(dfs: Dict[str, pd.DataFrame]) -> None:\n",
    "    inspector = reflection.Inspector.from_engine(engine)\n",
    "    existing_tables = inspector.get_table_names()\n",
    "\n",
    "    for table_name, df in dfs.items():\n",
    "        # check if table already exists\n",
    "        if table_name in existing_tables:\n",
    "            # if there are no changes to the table, do not write to it\n",
    "            existing_df = pd.read_sql_table(table_name, engine)\n",
    "            if df.shape == existing_df.shape and df.equals(existing_df):\n",
    "                print(f\"No changes detected for table {table_name}. Skipping upload.\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"Table {table_name} does not exist. Creating a new one.\")\n",
    "        df.to_sql(table_name, engine, if_exists=\"replace\", index=False)\n",
    "        print(f\"Uploaded DataFrame to table {table_name}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
