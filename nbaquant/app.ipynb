{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Player Data Analysis Project\n",
    "\n",
    "## Project Outline\n",
    "\n",
    "1. **Introduction**\n",
    "   - Overview of the project\n",
    "   - Goals and objectives\n",
    "\n",
    "2. **Data Collection**\n",
    "   - Import necessary libraries\n",
    "   - Fetch player data from the NBA API\n",
    "\n",
    "3. **Data Processing**\n",
    "   - Load data into a Pandas DataFrame\n",
    "   - Data cleaning and transformation\n",
    "\n",
    "4. **Data Analysis**\n",
    "   - Exploratory data analysis (EDA)\n",
    "   - Visualizations\n",
    "\n",
    "5. **Conclusion**\n",
    "   - Summary of findings\n",
    "   - Future work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python\n",
    "\n",
    "This project is written in Python, which means that Python must be installed in your environment to run the project. The minimum supported version is 3.10.\n",
    "\n",
    "#### Windows\n",
    "\n",
    "You can use the Windows package manager `winget`, or the [installer](https://www.python.org/downloads/windows/) from the website.\n",
    "```powershell\n",
    "# you can change the version in the package name to your desired version\n",
    "winget install Python.Python.3.12\n",
    "```\n",
    "\n",
    "#### MacOS\n",
    "Python is already installed by default on recent versions of MacOS. If you have an older version that is not supported, you can use the [Homebrew](https://brew.sh/) package manager to install it, or the [installer](https://www.python.org/downloads/macos/) from the website.\n",
    "```zsh\n",
    "brew install python\n",
    "```\n",
    "\n",
    "#### Linux\n",
    "Python is already installed by default on most distributions of Linux. If it isn't, you can use your distribution's package manager to install Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Virtual Environment\n",
    "\n",
    "It's generally recommended that you use a virtual environment (or venv) for this project. That way, all dependencies can be installed for the project without affecting the rest of your system. You can create a venv with Python:\n",
    "\n",
    "```bash\n",
    "python -m venv .venv\n",
    "```\n",
    "\n",
    "To activate the virtual environment in your shell, you can use the following commands.\n",
    "\n",
    "On Windows:\n",
    "\n",
    "```powershell\n",
    ".venv\\Scripts\\activate\n",
    "```\n",
    "\n",
    "On other operating systems:\n",
    "\n",
    "```bash\n",
    ".venv/bin/activate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "\n",
    "This project uses [Poetry](https://python-poetry.org/) to manage its dependencies. You can install the dependencies with the `poetry` command:\n",
    "\n",
    "`poetry install`\n",
    "\n",
    "If you don't want to use Poetry, a `requirements.txt` is also provided. You can install this using `pip`:\n",
    "\n",
    "`pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Variables\n",
    "\n",
    "We will load all our environment variables from a `.env` file, if one is provided.\n",
    "\n",
    "If database information is provided, all dataframes used for analysis are uploaded to it. We use [Microsoft SQL Server](https://www.microsoft.com/en-us/sql-server/sql-server-downloads) by default but any kind of database is supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "DB_TYPE = os.getenv(\"DB_TYPE\", \"sqlserver\")\n",
    "DB_USER = os.getenv(\"DB_USER\", \"sqladmin\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\", \"localhost\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\", \"1433\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"dataframes\")\n",
    "DB_DRIVER = os.getenv(\"DB_DRIVER\") # some databases require a database driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presentation\n",
    "\n",
    "By default, Pandas dataframes are truncated when they are printed. We want to be able to view all of the data at once, so we embed the dataframe in a scrollable element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "def custom_scrollable_display(df: pd.DataFrame, max_height=400):\n",
    "    \"\"\"\n",
    "    Custom display function to render DataFrames as scrollable elements.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: The DataFrame to display.\n",
    "    - max_height: The maximum height of the scrollable area in pixels.\n",
    "    \"\"\"\n",
    "    style = f\"\"\"\n",
    "    <style>\n",
    "    .scrollable-dataframe {{\n",
    "        display: inline-block;\n",
    "        white-space: nowrap;\n",
    "        overflow-x: scroll;\n",
    "        max-height: {max_height}px;\n",
    "        overflow-y: scroll;\n",
    "    }}\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    display(HTML(style + f'<div class=\"scrollable-dataframe\">{df.to_html()}</div>'))\n",
    "\n",
    "def custom_display_hook(df):\n",
    "    custom_scrollable_display(df)\n",
    "    return \"\"\n",
    "\n",
    "# hook up the custom display function to the automatic printer\n",
    "InteractiveShell.instance().display_formatter.formatters['text/html'].for_type(pd.DataFrame, custom_display_hook);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Commit Hooks (Developer Only)\n",
    "\n",
    "This notebook uses `nbstripout` to strip notebook output from Git commits. If you are committing code, please run the following command to set up the Git filter.\n",
    "\n",
    "Poetry is required for the pre-commit hooks, so make sure it is installed before you commit code. You will also need to add the plugin `poetry-plugin-export` in order to run the export hook.\n",
    "```bash\n",
    "poetry self add poetry-plugin-export\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbstripout --install\n",
    "!pre-commit install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "\n",
    "### Fetch Player Data from NBA API\n",
    "\n",
    "`nba_api` provides static player and team information, which we will download here so that we can reuse it without requesting the API unnecessarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.static import players, teams\n",
    "PLAYERS_LIST_FILE = \"../data/players_list.csv\"\n",
    "TEAMS_LIST_FILE = \"../data/teams_list.csv\"\n",
    "\n",
    "if os.path.exists(PLAYERS_LIST_FILE):\n",
    "    players_list = pd.read_csv(PLAYERS_LIST_FILE)\n",
    "else:\n",
    "    players_list = pd.DataFrame(players.get_players())\n",
    "    players_list.to_csv(PLAYERS_LIST_FILE)\n",
    "\n",
    "if os.path.exists(TEAMS_LIST_FILE):\n",
    "    teams_list = pd.read_csv(TEAMS_LIST_FILE)\n",
    "else:\n",
    "    teams_list = pd.DataFrame(teams.get_teams())\n",
    "    teams_list.to_csv(TEAMS_LIST_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Game Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're only interested in games that are either in the regular season or in the playoffs. We'll add an enum to distinguish the type of game and use it to differentiate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class SeasonType(Enum):\n",
    "    PRESEASON = 1\n",
    "    REGULAR_SEASON = 2\n",
    "    ALL_STAR = 3\n",
    "    PLAYOFFS = 4\n",
    "    PLAY_IN = 5\n",
    "    NBA_CUP = 6\n",
    "class Season():\n",
    "    def __init__(self, season_id: int) -> None:\n",
    "        season_id_str = str(season_id)\n",
    "        self.season_type = SeasonType(int(season_id_str[0]))\n",
    "        self.season_year = int(season_id_str[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import leaguegamefinder\n",
    "from nba_api.stats.library.parameters import LeagueIDNullable, LeagueID\n",
    "START_SEASON = 2015\n",
    "END_SEASON = 2023\n",
    "GAMES_LIST_FILE = \"../data/games_list.csv\"\n",
    "if os.path.exists(GAMES_LIST_FILE):\n",
    "    games_list: pd.DataFrame = pd.read_csv(GAMES_LIST_FILE)\n",
    "else:\n",
    "    games_list = pd.DataFrame()\n",
    "    for season in range(START_SEASON, END_SEASON + 1):\n",
    "        # put season into the correct form e.g. 2023 -> 2023-24\n",
    "        season_str = f\"{season}-{str(season + 1)[2:]}\"\n",
    "        print(f\"Fetching games for season: {season_str}\", end=\"\\r\")\n",
    "        gamefinder = leaguegamefinder.LeagueGameFinder(season_nullable=season_str, league_id_nullable=LeagueIDNullable.nba)\n",
    "        games = gamefinder.get_data_frames()[0]\n",
    "        games_list = pd.concat([games_list, games], ignore_index=True)\n",
    "        time.sleep(0.6)\n",
    "    games_list.to_csv(GAMES_LIST_FILE, index=False)\n",
    "# games_list[\"SEASON_ID\"].unique()\n",
    "# games_list.loc[(games_list[\"TEAM_NAME\"] == \"San Antonio Spurs\") & (games_list[\"SEASON_ID\"] == 22023)]\n",
    "games_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Play by Plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import playbyplayv3\n",
    "from requests.exceptions import ReadTimeout\n",
    "# took 483 minutes to download up to 2012\n",
    "PBP_LIST_FILE = \"../data/pbp_list.csv\"\n",
    "if os.path.exists(PBP_LIST_FILE):\n",
    "    pbp_list = pd.read_csv(PBP_LIST_FILE)\n",
    "else:\n",
    "    unique_games_list = games_list.drop_duplicates(subset=\"GAME_ID\")\n",
    "    pbp_list = pd.DataFrame()\n",
    "    for index, row in unique_games_list.iterrows():\n",
    "        err = False\n",
    "        game_id = row[\"GAME_ID\"]\n",
    "        game_date = row[\"GAME_DATE\"]\n",
    "        season_id = row[\"SEASON_ID\"]\n",
    "        season = Season(season_id)\n",
    "        if season.season_type != SeasonType.REGULAR_SEASON and season.season_type != SeasonType.PLAYOFFS:\n",
    "            continue\n",
    "        print(f\"Fetching play by play for game {game_id} on {game_date}\", end=\"\\r\")\n",
    "        while True:\n",
    "            try:\n",
    "                pbpfinder = playbyplayv3.PlayByPlayV3(f\"{game_id:010}\")\n",
    "                break\n",
    "            except ReadTimeout as e:\n",
    "                print(f\"{e}! Try again\")\n",
    "            except Exception:\n",
    "                with open(\"../data/err.log\", \"a\") as f:\n",
    "                    print(f\"{game_id} does not have a play by play\", file=f)\n",
    "                err = True\n",
    "                break\n",
    "        if err:\n",
    "            continue\n",
    "        pbp = pbpfinder.get_data_frames()[0]\n",
    "        pbp_list = pd.concat([pbp_list, pbp], ignore_index=True)\n",
    "        time.sleep(0.6)\n",
    "    pbp_list.to_csv(PBP_LIST_FILE, index=False)\n",
    "pbp_list.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Box Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import boxscoreplayertrackv3\n",
    "from requests.exceptions import ReadTimeout\n",
    "# took 483 minutes to download up to 2012\n",
    "BOXSCORE_PT_LIST_FILE = \"../data/boxscore_pt_list.csv\"\n",
    "if os.path.exists(BOXSCORE_PT_LIST_FILE):\n",
    "    boxscore_pt_list = pd.read_csv(BOXSCORE_PT_LIST_FILE)\n",
    "else:\n",
    "    unique_games_list = games_list.drop_duplicates(subset=\"GAME_ID\")\n",
    "    boxscore_pt_list = pd.DataFrame()\n",
    "    for index, row in unique_games_list.iterrows():\n",
    "        err = False\n",
    "        game_id = row[\"GAME_ID\"]\n",
    "        game_date = row[\"GAME_DATE\"]\n",
    "        season_id = row[\"SEASON_ID\"]\n",
    "        season = Season(season_id)\n",
    "        if season.season_type != SeasonType.REGULAR_SEASON and season.season_type != SeasonType.PLAYOFFS:\n",
    "            continue\n",
    "        print(f\"Fetching box score for game {game_id} on {game_date}\", end=\"\\r\")\n",
    "        while True:\n",
    "            try:\n",
    "                boxscorefinder = boxscoreplayertrackv3.BoxScorePlayerTrackV3(f\"{game_id:010}\")\n",
    "                break\n",
    "            except ReadTimeout as e:\n",
    "                print(f\"{e}! Try again\")\n",
    "            except Exception:\n",
    "                with open(\"../data/err.log\", \"a\") as f:\n",
    "                    print(f\"{game_id} does not have a player track box score\", file=f)\n",
    "                err = True\n",
    "                break\n",
    "        if err:\n",
    "            continue\n",
    "        boxscore_pt = boxscorefinder.get_data_frames()[0]\n",
    "        boxscore_pt_list = pd.concat([boxscore_pt_list, boxscore_pt], ignore_index=True)\n",
    "        time.sleep(0.6)\n",
    "    boxscore_pt_list.to_csv(BOXSCORE_PT_LIST_FILE, index=False)\n",
    "boxscore_pt_list.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script true\n",
    "\n",
    "from nba_api.stats.endpoints import boxscoredefensivev2\n",
    "from requests.exceptions import ReadTimeout\n",
    "# took 483 minutes to download up to 2012\n",
    "BOXSCORE_DF_LIST_FILE = \"../data/boxscore_df_list.csv\"\n",
    "if os.path.exists(BOXSCORE_DF_LIST_FILE):\n",
    "    boxscore_df_list = pd.read_csv(BOXSCORE_DF_LIST_FILE)\n",
    "else:\n",
    "    unique_games_list = games_list.drop_duplicates(subset=\"GAME_ID\")\n",
    "    boxscore_df_list = pd.DataFrame()\n",
    "    for index, row in unique_games_list.iterrows():\n",
    "        err = False\n",
    "        game_id = row[\"GAME_ID\"]\n",
    "        game_date = row[\"GAME_DATE\"]\n",
    "        season_id = row[\"SEASON_ID\"]\n",
    "        season = Season(season_id)\n",
    "        if season.season_type != SeasonType.REGULAR_SEASON and season.season_type != SeasonType.PLAYOFFS:\n",
    "            continue\n",
    "        print(f\"Fetching box score for game {game_id} on {game_date}\", end=\"\\r\")\n",
    "        while True:\n",
    "            try:\n",
    "                boxscorefinder = boxscoredefensivev2.BoxScoreDefensiveV2(f\"{game_id:010}\")\n",
    "                break\n",
    "            except ReadTimeout as e:\n",
    "                print(f\"{e}! Try again\")\n",
    "            except Exception:\n",
    "                with open(\"../data/err.log\", \"a\") as f:\n",
    "                    print(f\"{game_id} does not have a defensive box score\", file=f)\n",
    "                err = True\n",
    "                break\n",
    "        if err:\n",
    "            continue\n",
    "        boxscore_df = boxscorefinder.get_data_frames()[0]\n",
    "        boxscore_df_list = pd.concat([boxscore_df_list, boxscore_df], ignore_index=True)\n",
    "        time.sleep(0.6)\n",
    "    boxscore_df_list.to_csv(BOXSCORE_DF_LIST_FILE, index=False)\n",
    "boxscore_df_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script true\n",
    "\n",
    "from nba_api.stats.endpoints import boxscoretraditionalv3\n",
    "from requests.exceptions import ReadTimeout\n",
    "# took 483 minutes to download up to 2012\n",
    "BOXSCORE_TD_LIST_FILE = \"../data/boxscore_td_list.csv\"\n",
    "if os.path.exists(BOXSCORE_TD_LIST_FILE):\n",
    "    boxscore_td_list = pd.read_csv(BOXSCORE_TD_LIST_FILE)\n",
    "else:\n",
    "    unique_games_list = games_list.drop_duplicates(subset=\"GAME_ID\")\n",
    "    boxscore_td_list = pd.DataFrame()\n",
    "    for index, row in unique_games_list.iterrows():\n",
    "        err = False\n",
    "        game_id = row[\"GAME_ID\"]\n",
    "        game_date = row[\"GAME_DATE\"]\n",
    "        season_id = row[\"SEASON_ID\"]\n",
    "        season = Season(season_id)\n",
    "        if season.season_type != SeasonType.REGULAR_SEASON and season.season_type != SeasonType.PLAYOFFS:\n",
    "            continue\n",
    "        print(f\"Fetching box score for game {game_id} on {game_date}\", end=\"\\r\")\n",
    "        while True:\n",
    "            try:\n",
    "                boxscorefinder = boxscoretraditionalv3.BoxScoreTraditionalV3(f\"{game_id:010}\")\n",
    "                break\n",
    "            except ReadTimeout as e:\n",
    "                print(f\"{e}! Try again\")\n",
    "            except Exception:\n",
    "                with open(\"../data/err.log\", \"a\") as f:\n",
    "                    print(f\"{game_id} does not have a traditional box score\", file=f)\n",
    "                err = True\n",
    "                break\n",
    "        if err:\n",
    "            continue\n",
    "        boxscore_td = boxscorefinder.get_data_frames()[0]\n",
    "        boxscore_td_list = pd.concat([boxscore_td_list, boxscore_td], ignore_index=True)\n",
    "        time.sleep(0.6)\n",
    "    boxscore_td_list.to_csv(BOXSCORE_TD_LIST_FILE, index=False)\n",
    "boxscore_td_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script true\n",
    "\n",
    "from nba_api.stats.endpoints import boxscoreadvancedv3\n",
    "from requests.exceptions import ReadTimeout\n",
    "# took 483 minutes to download up to 2012\n",
    "BOXSCORE_AD_LIST_FILE = \"../data/boxscore_ad_list.csv\"\n",
    "if os.path.exists(BOXSCORE_AD_LIST_FILE):\n",
    "    boxscore_ad_list = pd.read_csv(BOXSCORE_AD_LIST_FILE)\n",
    "else:\n",
    "    unique_games_list = games_list.drop_duplicates(subset=\"GAME_ID\")\n",
    "    boxscore_ad_list = pd.DataFrame()\n",
    "    for index, row in unique_games_list.iterrows():\n",
    "        err = False\n",
    "        game_id = row[\"GAME_ID\"]\n",
    "        game_date = row[\"GAME_DATE\"]\n",
    "        season_id = row[\"SEASON_ID\"]\n",
    "        season = Season(season_id)\n",
    "        if season.season_type != SeasonType.REGULAR_SEASON and season.season_type != SeasonType.PLAYOFFS:\n",
    "            continue\n",
    "        print(f\"Fetching box score for game {game_id} on {game_date}\", end=\"\\r\")\n",
    "        while True:\n",
    "            try:\n",
    "                boxscorefinder = boxscoreadvancedv3.BoxScoreAdvancedV3(f\"{game_id:010}\")\n",
    "                break\n",
    "            except ReadTimeout as e:\n",
    "                print(f\"{e}! Try again\")\n",
    "            except Exception:\n",
    "                with open(\"../data/err.log\", \"a\") as f:\n",
    "                    print(f\"{game_id} does not have an advanced box score\", file=f)\n",
    "                err = True\n",
    "                break\n",
    "        if err:\n",
    "            continue\n",
    "        boxscore_ad = boxscorefinder.get_data_frames()[0]\n",
    "        boxscore_ad_list = pd.concat([boxscore_ad_list, boxscore_ad], ignore_index=True)\n",
    "        time.sleep(0.6)\n",
    "    boxscore_ad_list.to_csv(BOXSCORE_AD_LIST_FILE, index=False)\n",
    "boxscore_ad_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Four Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script true\n",
    "\n",
    "from nba_api.stats.endpoints import boxscorefourfactorsv3\n",
    "from requests.exceptions import ReadTimeout\n",
    "# took 483 minutes to download up to 2012\n",
    "BOXSCORE_FF_LIST_FILE = \"../data/boxscore_ff_list.csv\"\n",
    "if os.path.exists(BOXSCORE_FF_LIST_FILE):\n",
    "    boxscore_ff_list = pd.read_csv(BOXSCORE_FF_LIST_FILE)\n",
    "else:\n",
    "    unique_games_list = games_list.drop_duplicates(subset=\"GAME_ID\")\n",
    "    boxscore_ff_list = pd.DataFrame()\n",
    "    for index, row in unique_games_list.iterrows():\n",
    "        err = False\n",
    "        game_id = row[\"GAME_ID\"]\n",
    "        game_date = row[\"GAME_DATE\"]\n",
    "        season_id = row[\"SEASON_ID\"]\n",
    "        season = Season(season_id)\n",
    "        if season.season_type != SeasonType.REGULAR_SEASON and season.season_type != SeasonType.PLAYOFFS:\n",
    "            continue\n",
    "        print(f\"Fetching box score for game {game_id} on {game_date}\", end=\"\\r\")\n",
    "        while True:\n",
    "            try:\n",
    "                boxscorefinder = boxscorefourfactorsv3.BoxScoreFourFactorsV3(f\"{game_id:010}\")\n",
    "                break\n",
    "            except ReadTimeout as e:\n",
    "                print(f\"{e}! Try again\")\n",
    "            except Exception:\n",
    "                with open(\"../data/err.log\", \"a\") as f:\n",
    "                    print(f\"{game_id} does not have a four factors box score\", file=f)\n",
    "                err = True\n",
    "                break\n",
    "        if err:\n",
    "            continue\n",
    "        boxscore_ff = boxscorefinder.get_data_frames()[0]\n",
    "        boxscore_ff_list = pd.concat([boxscore_ff_list, boxscore_ff], ignore_index=True)\n",
    "        time.sleep(0.6)\n",
    "    boxscore_ff_list.to_csv(BOXSCORE_FF_LIST_FILE, index=False)\n",
    "boxscore_ff_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hustle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script true\n",
    "\n",
    "from nba_api.stats.endpoints import boxscorehustlev2\n",
    "from requests.exceptions import ReadTimeout\n",
    "# took 483 minutes to download up to 2012\n",
    "BOXSCORE_HS_LIST_FILE = \"../data/boxscore_hs_list.csv\"\n",
    "if os.path.exists(BOXSCORE_HS_LIST_FILE):\n",
    "    boxscore_hs_list = pd.read_csv(BOXSCORE_HS_LIST_FILE)\n",
    "else:\n",
    "    unique_games_list = games_list.drop_duplicates(subset=\"GAME_ID\")\n",
    "    boxscore_hs_list = pd.DataFrame()\n",
    "    for index, row in unique_games_list.iterrows():\n",
    "        err = False\n",
    "        game_id = row[\"GAME_ID\"]\n",
    "        game_date = row[\"GAME_DATE\"]\n",
    "        season_id = row[\"SEASON_ID\"]\n",
    "        season = Season(season_id)\n",
    "        if season.season_type != SeasonType.REGULAR_SEASON and season.season_type != SeasonType.PLAYOFFS:\n",
    "            continue\n",
    "        print(f\"Fetching box score for game {game_id} on {game_date}\", end=\"\\r\")\n",
    "        while True:\n",
    "            try:\n",
    "                boxscorefinder = boxscorehustlev2.BoxScoreHustleV2(f\"{game_id:010}\")\n",
    "                break\n",
    "            except ReadTimeout as e:\n",
    "                print(f\"{e}! Try again\")\n",
    "            except Exception:\n",
    "                with open(\"../data/err.log\", \"a\") as f:\n",
    "                    print(f\"{game_id} does not have a hustle box score\", file=f)\n",
    "                err = True\n",
    "                break\n",
    "        if err:\n",
    "            continue\n",
    "        boxscore_hs = boxscorefinder.get_data_frames()[0]\n",
    "        boxscore_hs_list = pd.concat([boxscore_hs_list, boxscore_hs], ignore_index=True)\n",
    "        time.sleep(0.6)\n",
    "    boxscore_hs_list.to_csv(BOXSCORE_HS_LIST_FILE, index=False)\n",
    "boxscore_hs_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script true\n",
    "\n",
    "from nba_api.stats.endpoints import boxscorematchupsv3\n",
    "from requests.exceptions import ReadTimeout\n",
    "# took 483 minutes to download up to 2012\n",
    "BOXSCORE_MU_LIST_FILE = \"../data/boxscore_mu_list.csv\"\n",
    "if os.path.exists(BOXSCORE_MU_LIST_FILE):\n",
    "    boxscore_mu_list = pd.read_csv(BOXSCORE_MU_LIST_FILE)\n",
    "else:\n",
    "    unique_games_list = games_list.drop_duplicates(subset=\"GAME_ID\")\n",
    "    boxscore_mu_list = pd.DataFrame()\n",
    "    for index, row in unique_games_list.iterrows():\n",
    "        err = False\n",
    "        game_id = row[\"GAME_ID\"]\n",
    "        game_date = row[\"GAME_DATE\"]\n",
    "        season_id = row[\"SEASON_ID\"]\n",
    "        season = Season(season_id)\n",
    "        if season.season_type != SeasonType.REGULAR_SEASON and season.season_type != SeasonType.PLAYOFFS:\n",
    "            continue\n",
    "        print(f\"Fetching box score for game {game_id} on {game_date}\", end=\"\\r\")\n",
    "        while True:\n",
    "            try:\n",
    "                boxscorefinder = boxscorematchupsv3.BoxScoreMatchupsV3(f\"{game_id:010}\")\n",
    "                break\n",
    "            except ReadTimeout as e:\n",
    "                print(f\"{e}! Try again\")\n",
    "            except Exception:\n",
    "                with open(\"../data/err.log\", \"a\") as f:\n",
    "                    print(f\"{game_id} does not have a matchup box score\", file=f)\n",
    "                err = True\n",
    "                break\n",
    "        if err:\n",
    "            continue\n",
    "        boxscore_mu = boxscorefinder.get_data_frames()[0]\n",
    "        boxscore_mu_list = pd.concat([boxscore_mu_list, boxscore_mu], ignore_index=True)\n",
    "        time.sleep(0.6)\n",
    "    boxscore_mu_list.to_csv(BOXSCORE_MU_LIST_FILE, index=False)\n",
    "boxscore_mu_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script true\n",
    "\n",
    "from nba_api.stats.endpoints import boxscoremiscv3\n",
    "from requests.exceptions import ReadTimeout\n",
    "# took 483 minutes to download up to 2012\n",
    "BOXSCORE_MS_LIST_FILE = \"../data/boxscore_ms_list.csv\"\n",
    "if os.path.exists(BOXSCORE_MS_LIST_FILE):\n",
    "    boxscore_ms_list = pd.read_csv(BOXSCORE_MS_LIST_FILE)\n",
    "else:\n",
    "    unique_games_list = games_list.drop_duplicates(subset=\"GAME_ID\")\n",
    "    boxscore_ms_list = pd.DataFrame()\n",
    "    for index, row in unique_games_list.iterrows():\n",
    "        err = False\n",
    "        game_id = row[\"GAME_ID\"]\n",
    "        game_date = row[\"GAME_DATE\"]\n",
    "        season_id = row[\"SEASON_ID\"]\n",
    "        season = Season(season_id)\n",
    "        if season.season_type != SeasonType.REGULAR_SEASON and season.season_type != SeasonType.PLAYOFFS:\n",
    "            continue\n",
    "        print(f\"Fetching box score for game {game_id} on {game_date}\", end=\"\\r\")\n",
    "        while True:\n",
    "            try:\n",
    "                boxscorefinder = boxscoremiscv3.BoxScoreMiscV3(f\"{game_id:010}\")\n",
    "                break\n",
    "            except ReadTimeout as e:\n",
    "                print(f\"{e}! Try again\")\n",
    "            except Exception:\n",
    "                with open(\"../data/err.log\", \"a\") as f:\n",
    "                    print(f\"{game_id} does not have a miscellaneous box score\", file=f)\n",
    "                err = True\n",
    "                break\n",
    "        if err:\n",
    "            continue\n",
    "        boxscore_ms = boxscorefinder.get_data_frames()[0]\n",
    "        boxscore_ms_list = pd.concat([boxscore_ms_list, boxscore_ms], ignore_index=True)\n",
    "        time.sleep(0.6)\n",
    "    boxscore_ms_list.to_csv(BOXSCORE_MS_LIST_FILE, index=False)\n",
    "boxscore_ms_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script true\n",
    "\n",
    "from nba_api.stats.endpoints import boxscorescoringv3\n",
    "from requests.exceptions import ReadTimeout\n",
    "# took 483 minutes to download up to 2012\n",
    "BOXSCORE_SC_LIST_FILE = \"../data/boxscore_sc_list.csv\"\n",
    "if os.path.exists(BOXSCORE_SC_LIST_FILE):\n",
    "    boxscore_sc_list = pd.read_csv(BOXSCORE_SC_LIST_FILE)\n",
    "else:\n",
    "    unique_games_list = games_list.drop_duplicates(subset=\"GAME_ID\")\n",
    "    boxscore_sc_list = pd.DataFrame()\n",
    "    for index, row in unique_games_list.iterrows():\n",
    "        err = False\n",
    "        game_id = row[\"GAME_ID\"]\n",
    "        game_date = row[\"GAME_DATE\"]\n",
    "        season_id = row[\"SEASON_ID\"]\n",
    "        season = Season(season_id)\n",
    "        if season.season_type != SeasonType.REGULAR_SEASON and season.season_type != SeasonType.PLAYOFFS:\n",
    "            continue\n",
    "        print(f\"Fetching box score for game {game_id} on {game_date}\", end=\"\\r\")\n",
    "        while True:\n",
    "            try:\n",
    "                boxscorefinder = boxscorescoringv3.BoxScoreScoringV3(f\"{game_id:010}\")\n",
    "                break\n",
    "            except ReadTimeout as e:\n",
    "                print(f\"{e}! Try again\")\n",
    "            except Exception:\n",
    "                with open(\"../data/err.log\", \"a\") as f:\n",
    "                    print(f\"{game_id} does not have a scoring box score\", file=f)\n",
    "                err = True\n",
    "                break\n",
    "        if err:\n",
    "            continue\n",
    "        boxscore_sc = boxscorefinder.get_data_frames()[0]\n",
    "        boxscore_sc_list = pd.concat([boxscore_sc_list, boxscore_sc], ignore_index=True)\n",
    "        time.sleep(0.6)\n",
    "    boxscore_sc_list.to_csv(BOXSCORE_SC_LIST_FILE, index=False)\n",
    "boxscore_sc_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script true\n",
    "\n",
    "from nba_api.stats.endpoints import boxscoreusagev3\n",
    "from requests.exceptions import ReadTimeout\n",
    "# took 483 minutes to download up to 2012\n",
    "BOXSCORE_US_LIST_FILE = \"../data/boxscore_us_list.csv\"\n",
    "if os.path.exists(BOXSCORE_US_LIST_FILE):\n",
    "    boxscore_us_list = pd.read_csv(BOXSCORE_US_LIST_FILE)\n",
    "else:\n",
    "    unique_games_list = games_list.drop_duplicates(subset=\"GAME_ID\")\n",
    "    boxscore_us_list = pd.DataFrame()\n",
    "    for index, row in unique_games_list.iterrows():\n",
    "        err = False\n",
    "        game_id = row[\"GAME_ID\"]\n",
    "        game_date = row[\"GAME_DATE\"]\n",
    "        season_id = row[\"SEASON_ID\"]\n",
    "        season = Season(season_id)\n",
    "        if season.season_type != SeasonType.REGULAR_SEASON and season.season_type != SeasonType.PLAYOFFS:\n",
    "            continue\n",
    "        print(f\"Fetching box score for game {game_id} on {game_date}\", end=\"\\r\")\n",
    "        while True:\n",
    "            try:\n",
    "                boxscorefinder = boxscoreusagev3.BoxScoreUsageV3(f\"{game_id:010}\")\n",
    "                break\n",
    "            except ReadTimeout as e:\n",
    "                print(f\"{e}! Try again\")\n",
    "            except Exception:\n",
    "                with open(\"../data/err.log\", \"a\") as f:\n",
    "                    print(f\"{game_id} does not have a usage box score\", file=f)\n",
    "                err = True\n",
    "                break\n",
    "        if err:\n",
    "            continue\n",
    "        boxscore_us = boxscorefinder.get_data_frames()[0]\n",
    "        boxscore_us_list = pd.concat([boxscore_us_list, boxscore_us], ignore_index=True)\n",
    "        time.sleep(0.6)\n",
    "    boxscore_us_list.to_csv(BOXSCORE_US_LIST_FILE, index=False)\n",
    "boxscore_us_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our analysis will consider only the last two years, so we'll get rid of data from before that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_year = games_list['SEASON_ID'].astype(str).str[1:].astype(int)\n",
    "games_list['season_year'] = season_year\n",
    "current_season_year = 2023  # Replace with the current season's start year\n",
    "games_list = games_list[games_list['season_year'].isin([current_season_year, current_season_year - 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp_list = pbp_list[pbp_list['gameId'].isin(games_list[\"GAME_ID\"].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxscore_pt_list = boxscore_pt_list[boxscore_pt_list['gameId'].isin(games_list[\"GAME_ID\"].unique())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unnecessary Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of this data isn't useful to us, so we'll drop it to ignore the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp_columns_to_drop = [\"actionNumber\", \"pointsTotal\", \"videoAvailable\", \"actionId\", \"playerNameI\", \"teamTricode\"]\n",
    "pbp_list.drop(columns=[col for col in pbp_columns_to_drop if col in pbp_list.columns], inplace=True)\n",
    "pbp_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bspt_columns_to_drop = [\"teamCity\", \"teamName\", \"teamTricode\", \"teamSlug\", \"playerNameI\", \"teamTricode\", \"playerSlug\", \"jerseyNum\"]\n",
    "boxscore_pt_list.drop(columns=[col for col in bspt_columns_to_drop if col in boxscore_pt_list.columns], inplace=True)\n",
    "boxscore_pt_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save on memory, we will also turn variables that can be understood as categorical variables into that type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp_categorical_columns = [\"gameId\", \"teamId\", \"shotResult\", \"isFieldGoal\", \"location\", \"actionType\", \"subType\", \"personId\", \"playerName\"]\n",
    "pbp_list[pbp_categorical_columns] = pbp_list[pbp_categorical_columns].astype(\"category\")\n",
    "pbp_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bspt_categorical_columns = [\"gameId\", \"teamId\", \"personId\", \"firstName\", \"familyName\", \"nameI\",  \"position\"]\n",
    "boxscore_pt_list[bspt_categorical_columns] = boxscore_pt_list[bspt_categorical_columns].astype(\"category\")\n",
    "boxscore_pt_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll transform the clock data from a string into the total number of seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pbp_list[\"clock\"].dtype != \"int64\":\n",
    "    pbp_list[\"clock\"] = pbp_list[\"clock\"].astype(str)\n",
    "    pbp_list[\"minutes\"] = pbp_list[\"clock\"].str[2:4].astype(int)\n",
    "    pbp_list[\"seconds\"] = pbp_list[\"clock\"].str[5:7].astype(int)\n",
    "    pbp_list[\"clock\"] = pbp_list[\"minutes\"] * 60 + pbp_list[\"seconds\"]\n",
    "    pbp_list.drop(columns=[\"minutes\", \"seconds\"], inplace=True)\n",
    "pbp_list[\"clock\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if boxscore_pt_list[\"minutes\"].dtype != \"int64\":\n",
    "    boxscore_pt_list[\"minutes\"] = boxscore_pt_list[\"minutes\"].astype(str)\n",
    "    boxscore_pt_list[\"mins\"] = boxscore_pt_list[\"minutes\"].str[:-3].astype(int)\n",
    "    boxscore_pt_list[\"seconds\"] = boxscore_pt_list[\"minutes\"].str[-2:].astype(int)\n",
    "    boxscore_pt_list[\"minutes\"] = boxscore_pt_list[\"mins\"] * 60 + boxscore_pt_list[\"seconds\"]\n",
    "    boxscore_pt_list.drop(columns=[\"mins\", \"seconds\"], inplace=True)\n",
    "boxscore_pt_list[\"minutes\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defensive Plus/Minus in the Paint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to determine which players are the best in protecting the paint, we will calculate how many field goals are scored against them in the paint when they are on the floor vs. when they are not, creating a plus/minus. Note that this is similar to, but distinct from, the existing defensive rim field goals stat. That stat is specific to shots that the players were identified as defending. This stat is broader and encompasses all points in the paint, which allows us to capture paint impact beyond defending the shooter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at a range of players so that we can have a general view of how the stats look on them.\n",
    "- Rudy Gobert: defensive player of the year\n",
    "- Walter Kessler: a young elite rim protector\n",
    "- Evan Mobley: a young versatile defender with a lot of upside\n",
    "- Ivica Zubac: one of the league's most underrated rim protectors\n",
    "- Jusuf Nurkic: veteran traditional rim protector who is past his prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defpmpaint(player_id: int, player_name: str) -> pd.DataFrame:\n",
    "    bs_player_games = boxscore_pt_list[boxscore_pt_list['personId'] == player_id]\n",
    "    bs_player_games = bs_player_games[bs_player_games[\"comment\"].isna()]\n",
    "\n",
    "    games_with_player = pbp_list[pbp_list['gameId'].isin(bs_player_games['gameId'].unique())]\n",
    "\n",
    "    #games_with_player = pbp_list.groupby(\"gameId\", observed=True).filter(lambda row: player_id in row[\"personId\"].values)\n",
    "    games_with_player[\"gameId\"].unique()\n",
    "    games_with_player = games_with_player[\n",
    "        (games_with_player['actionType'].isin(['Substitution', 'Missed Shot', 'Made Shot']))\n",
    "    ]\n",
    "\n",
    "    # Further filter for shots by the opposing team and shot distance < 3\n",
    "    games_with_player = games_with_player[\n",
    "        ((games_with_player['actionType'].isin(['Missed Shot', 'Made Shot']))) |\n",
    "        (games_with_player['actionType'] == 'Substitution')\n",
    "    ]\n",
    "    if 'totalMinutes' not in games_with_player.columns:\n",
    "        total_minutes_per_game = games_with_player.groupby('gameId', observed=True)['period'].nunique() * 720\n",
    "        games_with_player = games_with_player.merge(total_minutes_per_game.rename('totalMinutes'), on='gameId')\n",
    "\n",
    "    unique_games = games_with_player[['gameId', 'totalMinutes']].drop_duplicates()\n",
    "\n",
    "    total_minutes_all_games = unique_games['totalMinutes'].sum()\n",
    "    total_minutes_all_games\n",
    "    games_with_player[\"isOnFloor\"] = False\n",
    "    games_with_player[\"playerTeamId\"] = None\n",
    "\n",
    "    for game_id, game_data in games_with_player.groupby('gameId', observed=True):\n",
    "\n",
    "        # check if the player is starting and set onFloor to true or false based on that\n",
    "        game_bs = boxscore_pt_list[boxscore_pt_list[\"gameId\"] == game_id]\n",
    "        player_bs = game_bs.loc[game_bs[\"personId\"] == player_id]\n",
    "        player_team_id = player_bs.loc[:, \"teamId\"].values[0]\n",
    "        player_position = player_bs.loc[:, \"position\"]\n",
    "        games_with_player.loc[games_with_player['gameId'] == game_id, 'playerTeamId'] = player_team_id\n",
    "        # print(game_id)\n",
    "        # print(game_bs)\n",
    "        on_floor = not isinstance(player_position.values[0], float)\n",
    "        #print(player_position.values[0], on_floor)\n",
    "        # player_team_id = None\n",
    "        indices = game_data.index.tolist()\n",
    "        \n",
    "        for i in range(len(game_data)):\n",
    "            row = game_data.iloc[i]\n",
    "            # if player_team_id is None and row[\"personId\"] == player_id:\n",
    "            #     # Set the player's teamId from this row (assumed to be correct for the whole game)\n",
    "            #     player_team_id = row['teamId']\n",
    "            #     games_with_player.loc[games_with_player['gameId'] == game_id, 'playerTeamId'] = player_team_id\n",
    "            \n",
    "            if row['actionType'] == 'Substitution':\n",
    "                sub_description = row['description']\n",
    "                if f'FOR {player_name}' in sub_description:\n",
    "                    # print(f\"SUB found: {sub_description} in game {game_id}\")\n",
    "                    on_floor = False  # Player subbed out\n",
    "                elif player_name in sub_description:\n",
    "                    # print(f\"SUB found: {sub_description} in game {game_id}\")\n",
    "                    on_floor = True  # Player subbed in\n",
    "\n",
    "            # Update the isOnFloor status\n",
    "            games_with_player.at[indices[i], 'isOnFloor'] = on_floor\n",
    "    games_with_player.head()\n",
    "    # filter shots to visitor only\n",
    "    shots = games_with_player[\n",
    "        ((games_with_player['actionType'].isin(['Missed Shot', 'Made Shot'])) & \n",
    "        (games_with_player['teamId'] != games_with_player[\"playerTeamId\"]))\n",
    "    ].copy()\n",
    "\n",
    "    shots.loc[:, 'isLayup'] = shots['subType'].str.contains('Layup', case=False, na=False)\n",
    "    shots.loc[:, 'isDunk'] = shots['subType'].str.contains('Dunk', case=False, na=False)\n",
    "    shots.loc[:, 'isHook'] = shots['subType'].str.contains('Hook', case=False, na=False)\n",
    "    shots.loc[:, 'isJump'] = shots['subType'].str.contains('Jump', case=False, na=False)\n",
    "\n",
    "    ldh_shots = shots[(shots[\"isLayup\"]) | (shots[\"isDunk\"]) | (shots[\"isHook\"])]\n",
    "\n",
    "    shots_on_floor = ldh_shots[ldh_shots['isOnFloor']]\n",
    "    shots_off_floor = ldh_shots[~ldh_shots['isOnFloor']]\n",
    "\n",
    "    player_minutes = boxscore_pt_list[boxscore_pt_list['personId'] == player_id][['gameId', 'minutes']].set_index('gameId')\n",
    "\n",
    "    shots_on_floor = shots_on_floor.join(player_minutes, on='gameId', how='inner', rsuffix='_on')\n",
    "    shots_off_floor = shots_off_floor.join(player_minutes, on='gameId', how='inner', rsuffix='_off')\n",
    "\n",
    "    # Calculate field goal attempts and percentage\n",
    "    def calculate_fg_stats(shots, minutes):\n",
    "        attempts = len(shots)\n",
    "        made = len(shots[shots['shotResult'] == 'Made'])\n",
    "        percentage = made / attempts if attempts > 0 else 0\n",
    "        fg_attempts_per_min = attempts / minutes if minutes > 0 else 0\n",
    "        fg_made_per_min = made / minutes if minutes > 0 else 0\n",
    "        return fg_attempts_per_min, fg_made_per_min, percentage\n",
    "\n",
    "    minutes_on_floor = player_minutes['minutes'].sum()\n",
    "    fg_attempts_per_min_on, fg_made_per_min_on, fg_percentage_on = calculate_fg_stats(shots_on_floor, minutes_on_floor)\n",
    "\n",
    "    # Calculate field goal stats when the player is off the floor\n",
    "    minutes_off_floor = total_minutes_all_games - minutes_on_floor\n",
    "    fg_attempts_per_min_off, fg_made_per_min_off, fg_percentage_off = calculate_fg_stats(shots_off_floor, minutes_off_floor)\n",
    "\n",
    "    # print(minutes_on_floor, total_minutes_all_games, minutes_on_floor / total_minutes_all_games)\n",
    "\n",
    "    # Print the adjusted field goal stats\n",
    "    # print(f\"Player On Floor - FG Attempts per 36 Min: {fg_attempts_per_min_on * 36 * 60:.3f}, FG%: {fg_percentage_on:.2%}\")\n",
    "    # print(f\"Player Off Floor - FG Attempts per 36 Min: {fg_attempts_per_min_off * 36 * 60:.3f}, FG%: {fg_percentage_off:.2%}\")\n",
    "    return {\n",
    "        'player_id': player_id,\n",
    "        'player_name': player_name,\n",
    "        'fg_attempts_on': len(shots_on_floor),\n",
    "        'fg_attempts_per_min_on': fg_attempts_per_min_on * 36 * 60,\n",
    "        'fg_made_per_min_on': fg_made_per_min_on * 36 * 60,\n",
    "        'fg_percentage_on': fg_percentage_on,\n",
    "        'fg_attempts_off': len(shots_off_floor),\n",
    "        'fg_attempts_per_min_off': fg_attempts_per_min_off * 36 * 60,\n",
    "        'fg_made_per_min_off': fg_made_per_min_off * 36 * 60,\n",
    "        'fg_percentage_off': fg_percentage_off,\n",
    "        'percentage_delta': fg_percentage_on - fg_percentage_off,\n",
    "    }\n",
    "players = [\n",
    "    (1629027, \"Young\"),\n",
    "    (1630169, \"Haliburton\"),\n",
    "    (203497, \"Gobert\"),\n",
    "    (1631117, \"Kessler\"),\n",
    "    (1627826, \"Zubac\"),\n",
    "    (1630596, \"Mobley\"),\n",
    "    (203994, \"Nurkic\")\n",
    "]\n",
    "\n",
    "players_dfpm = []\n",
    "for player_id, player_name in players:\n",
    "    result = defpmpaint(player_id, player_name)\n",
    "    players_dfpm.append(result)\n",
    "\n",
    "# Step 4: Convert the list of results to a dataframe\n",
    "players_dfpm = pd.DataFrame(players_dfpm)\n",
    "players_dfpm.sort_values(\"percentage_delta\").style.format({\n",
    "    'fg_attempts_per_min_on': '{:,.2f}'.format,\n",
    "    'fg_made_per_min_on': '{:,.2f}'.format,\n",
    "    'fg_percentage_on': '{:,.2%}'.format,\n",
    "    'fg_attempts_per_min_off': '{:,.2f}'.format,\n",
    "    'fg_made_per_min_off': '{:,.2f}'.format,\n",
    "    'fg_percentage_off': '{:,.2%}'.format,\n",
    "    'percentage_delta': '{:,.2%}'.format,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defensive Rim Field Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our defensive plus/minus, let's compare it to the existing defensive rim field goals stat and see how the players stack up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_ids = [player[0] for player in players]\n",
    "\n",
    "# Filter for the players of interest\n",
    "boxscore_players = boxscore_pt_list[boxscore_pt_list['personId'].isin(player_ids)]\n",
    "\n",
    "# Group by personId and aggregate the stats\n",
    "rim_defense = boxscore_players.groupby('personId', observed=True).agg(\n",
    "    player_name=(\"familyName\", \"first\"),\n",
    "    total_defended_at_rim_made=('defendedAtRimFieldGoalsMade', 'sum'),\n",
    "    total_defended_at_rim_attempted=('defendedAtRimFieldGoalsAttempted', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate the overall defended field goal percentage at the rim\n",
    "rim_defense['defended_at_rim_field_goal_percentage'] = (\n",
    "    rim_defense['total_defended_at_rim_made'] / rim_defense['total_defended_at_rim_attempted'] * 100\n",
    ")\n",
    "\n",
    "# Output the result\n",
    "rim_defense.sort_values(\"defended_at_rim_field_goal_percentage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Reporting\n",
    "\n",
    "To create our final report from our analysis, we will be using Power BI. We have a Microsoft SQL Server database that our Power BI report will import the tables from. If no database is available, the dataframes will instead export as an Excel spreadsheet, which can be manually uploaded to Power BI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import ExcelWriter\n",
    "import sqlalchemy\n",
    "\n",
    "dfs = {\"defensive_plus_or_minus\": players_dfpm, \"rim_defense\": rim_defense}\n",
    "\n",
    "def upload_dataframes(dfs: Dict[str, pd.DataFrame]) -> None:\n",
    "    DATABASE_URL = f\"{DB_TYPE}://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}{'?driver=' if DB_DRIVER else ''}{DB_DRIVER.replace(' ', '+') if DB_DRIVER else ''}\"\n",
    "\n",
    "    engine = sqlalchemy.create_engine(DATABASE_URL)\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        print(\"Connection to the database was successful!\")\n",
    "\n",
    "    inspector = sqlalchemy.inspect(engine)\n",
    "    existing_tables = inspector.get_table_names()\n",
    "\n",
    "    for table_name, df in dfs.items():\n",
    "        # check if table already exists\n",
    "        if table_name in existing_tables:\n",
    "            # if there are no changes to the table, do not write to it\n",
    "            existing_df = pd.read_sql_table(table_name, engine)\n",
    "            if df.shape == existing_df.shape and df.equals(existing_df):\n",
    "                print(f\"No changes detected for table {table_name}. Skipping upload.\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"Table {table_name} does not exist. Creating a new one.\")\n",
    "        df.to_sql(table_name, engine, if_exists=\"replace\", index=False)\n",
    "        print(f\"Uploaded dataframe to table {table_name}.\")\n",
    "\n",
    "if DB_PASSWORD:\n",
    "    upload_dataframes(dfs)\n",
    "else:\n",
    "    EXCEL_MAX_ROWS = 1048575\n",
    "    excel_writer = pd.ExcelWriter(\"../data/dataframes.xlsx\")\n",
    "    for name, df in dfs.items():\n",
    "        df.head(EXCEL_MAX_ROWS).to_excel(excel_writer, sheet_name=name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
